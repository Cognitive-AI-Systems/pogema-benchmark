[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 180, "makespan": 31, "avg_agents_density": 0.027691819924071864, "runtime": 7.443888630717993, "a_collisions": 5, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 191, "makespan": 35, "avg_agents_density": 0.03284553336102281, "runtime": 8.449190717190504, "a_collisions": 4, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 139, "makespan": 27, "avg_agents_density": 0.028144678394204408, "runtime": 6.3655660431832075, "a_collisions": 0, "o_collisions": 3}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 137, "makespan": 25, "avg_agents_density": 0.026643843829583815, "runtime": 5.889876190572977, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 299, "makespan": 128, "avg_agents_density": 0.025096878671443966, "runtime": 30.384974932298064, "a_collisions": 40, "o_collisions": 5}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 315, "makespan": 128, "avg_agents_density": 0.032608311403582314, "runtime": 29.05968438088894, "a_collisions": 52, "o_collisions": 11}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 149, "makespan": 28, "avg_agents_density": 0.03022942153076391, "runtime": 6.834895957261324, "a_collisions": 4, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 341, "makespan": 84, "avg_agents_density": 0.032736841587209436, "runtime": 20.293625572696328, "a_collisions": 49, "o_collisions": 2}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 198, "makespan": 47, "avg_agents_density": 0.040871704267218804, "runtime": 11.439055651426315, "a_collisions": 7, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 167, "makespan": 32, "avg_agents_density": 0.03204843576993264, "runtime": 7.862587794661522, "a_collisions": 1, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 332, "makespan": 128, "avg_agents_density": 0.02312655922054718, "runtime": 30.532345166429877, "a_collisions": 7, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 364, "makespan": 128, "avg_agents_density": 0.03814479290168969, "runtime": 30.35221729427576, "a_collisions": 4, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 130, "makespan": 28, "avg_agents_density": 0.02811368010531841, "runtime": 6.5150646567344666, "a_collisions": 2, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 351, "makespan": 128, "avg_agents_density": 0.04432741074692027, "runtime": 30.06421715579927, "a_collisions": 1, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 129, "makespan": 28, "avg_agents_density": 0.04990578220589151, "runtime": 6.374023377895355, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 354, "makespan": 128, "avg_agents_density": 0.027413355253929392, "runtime": 31.33176176995039, "a_collisions": 15, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 258, "makespan": 128, "avg_agents_density": 0.028809475438046246, "runtime": 30.061983861029148, "a_collisions": 3, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 373, "makespan": 128, "avg_agents_density": 0.03393012770275062, "runtime": 30.84208862297237, "a_collisions": 34, "o_collisions": 11}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 780, "makespan": 128, "avg_agents_density": 0.038787212008650464, "runtime": 28.915563963353634, "a_collisions": 8, "o_collisions": 54}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 141, "makespan": 28, "avg_agents_density": 0.03085725159711554, "runtime": 6.568008964881301, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 220, "makespan": 76, "avg_agents_density": 0.0318425491391888, "runtime": 17.51705053076148, "a_collisions": 26, "o_collisions": 3}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 192, "makespan": 46, "avg_agents_density": 0.03540256094916423, "runtime": 9.992142673581839, "a_collisions": 8, "o_collisions": 8}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 213, "makespan": 88, "avg_agents_density": 0.03604134681547064, "runtime": 21.54691642522812, "a_collisions": 18, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 152, "makespan": 30, "avg_agents_density": 0.0481891957973735, "runtime": 7.07962441816926, "a_collisions": 5, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 308, "makespan": 128, "avg_agents_density": 0.02954922861258952, "runtime": 29.744203593581915, "a_collisions": 7, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 332, "makespan": 128, "avg_agents_density": 0.029542948327163525, "runtime": 31.481657456606627, "a_collisions": 0, "o_collisions": 7}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 172, "makespan": 30, "avg_agents_density": 0.032897440136404846, "runtime": 6.941576384007931, "a_collisions": 7, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 231, "makespan": 128, "avg_agents_density": 0.032324803150560244, "runtime": 29.297278251498938, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 257, "makespan": 128, "avg_agents_density": 0.032647930936984426, "runtime": 29.636136159300804, "a_collisions": 3, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 415, "makespan": 128, "avg_agents_density": 0.025045750119700304, "runtime": 30.05488571152091, "a_collisions": 11, "o_collisions": 7}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 292, "makespan": 128, "avg_agents_density": 0.03544862454974474, "runtime": 29.68645403161645, "a_collisions": 11, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 135, "makespan": 24, "avg_agents_density": 0.034285215790368966, "runtime": 5.694298762828112, "a_collisions": 4, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 187, "makespan": 51, "avg_agents_density": 0.028761412348515793, "runtime": 11.760612312704325, "a_collisions": 15, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-032"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 294, "makespan": 128, "avg_agents_density": 0.046889564339368243, "runtime": 29.573380678892136, "a_collisions": 13, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-033"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 149, "makespan": 30, "avg_agents_density": 0.057395997853435084, "runtime": 7.316697873175144, "a_collisions": 1, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-034"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 139, "makespan": 28, "avg_agents_density": 0.02962232970454463, "runtime": 7.209015207365155, "a_collisions": 1, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-035"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 218, "makespan": 57, "avg_agents_density": 0.030366669693304163, "runtime": 13.634086929261684, "a_collisions": 8, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-036"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 127, "SoC": 257, "makespan": 128, "avg_agents_density": 0.03816873535601014, "runtime": 30.42958747036755, "a_collisions": 33, "o_collisions": 3}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-037"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 307, "makespan": 128, "avg_agents_density": 0.044529203457894365, "runtime": 30.09495804272592, "a_collisions": 26, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-038"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 208, "makespan": 38, "avg_agents_density": 0.036754879962383746, "runtime": 9.132162040099502, "a_collisions": 14, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-039"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 439, "makespan": 128, "avg_agents_density": 0.03148643188801486, "runtime": 29.74056146852672, "a_collisions": 76, "o_collisions": 8}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-040"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 316, "makespan": 98, "avg_agents_density": 0.04706473012981413, "runtime": 23.77475055679679, "a_collisions": 0, "o_collisions": 3}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-041"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 298, "makespan": 128, "avg_agents_density": 0.03254838259576793, "runtime": 29.800708185881376, "a_collisions": 9, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-042"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 254, "makespan": 128, "avg_agents_density": 0.01589114510031062, "runtime": 29.415424613282084, "a_collisions": 3, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-043"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 152, "makespan": 24, "avg_agents_density": 0.028046800432760498, "runtime": 6.62176064401865, "a_collisions": 1, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-044"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 189, "makespan": 64, "avg_agents_density": 0.028202802991806664, "runtime": 15.790403014048934, "a_collisions": 13, "o_collisions": 2}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-045"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 284, "makespan": 128, "avg_agents_density": 0.03203551507229555, "runtime": 29.174255972728133, "a_collisions": 1, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-046"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 247, "makespan": 128, "avg_agents_density": 0.028193114994269283, "runtime": 31.379584664478898, "a_collisions": 62, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-047"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 113, "makespan": 19, "avg_agents_density": 0.027612181122207265, "runtime": 4.6124280747026205, "a_collisions": 1, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-048"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 309, "makespan": 128, "avg_agents_density": 0.03381181368609715, "runtime": 31.221206096932292, "a_collisions": 14, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-049"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 373, "makespan": 128, "avg_agents_density": 0.042019111712492056, "runtime": 30.415277855470777, "a_collisions": 9, "o_collisions": 40}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-050"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 394, "makespan": 128, "avg_agents_density": 0.027431489779262665, "runtime": 31.430053221061826, "a_collisions": 6, "o_collisions": 2}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-051"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 374, "makespan": 128, "avg_agents_density": 0.0197545099286536, "runtime": 29.576110143214464, "a_collisions": 0, "o_collisions": 39}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-052"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 384, "makespan": 78, "avg_agents_density": 0.04146684900680505, "runtime": 18.232591778039932, "a_collisions": 40, "o_collisions": 8}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-053"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 352, "makespan": 128, "avg_agents_density": 0.029686605885268127, "runtime": 29.780379742383957, "a_collisions": 40, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-054"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 155, "makespan": 30, "avg_agents_density": 0.027346797042584567, "runtime": 7.132320327684283, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-055"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 381, "makespan": 128, "avg_agents_density": 0.025747025504560157, "runtime": 30.214904718101025, "a_collisions": 149, "o_collisions": 3}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-056"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 292, "makespan": 128, "avg_agents_density": 0.029152586100924745, "runtime": 30.6560067422688, "a_collisions": 44, "o_collisions": 2}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-057"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 188, "makespan": 40, "avg_agents_density": 0.04261431360275736, "runtime": 9.374924462288618, "a_collisions": 10, "o_collisions": 2}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-058"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 186, "makespan": 56, "avg_agents_density": 0.02738745458971076, "runtime": 12.89590958878398, "a_collisions": 18, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-059"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 253, "makespan": 128, "avg_agents_density": 0.020779658024328823, "runtime": 31.25037219747901, "a_collisions": 1, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-060"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 103, "SoC": 233, "makespan": 104, "avg_agents_density": 0.03304616701957098, "runtime": 24.374493530020118, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-061"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 245, "makespan": 44, "avg_agents_density": 0.02723874738304196, "runtime": 10.080049632117152, "a_collisions": 5, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-062"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 181, "makespan": 32, "avg_agents_density": 0.03433108450973453, "runtime": 7.881415402516723, "a_collisions": 1, "o_collisions": 6}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-063"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 173, "makespan": 37, "avg_agents_density": 0.048017647702427384, "runtime": 8.717134110629559, "a_collisions": 15, "o_collisions": 3}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-064"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 448, "makespan": 128, "avg_agents_density": 0.04773288117646251, "runtime": 29.763323241844773, "a_collisions": 23, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-065"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 376, "makespan": 128, "avg_agents_density": 0.018192887348479916, "runtime": 31.692000899463892, "a_collisions": 6, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-066"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 267, "makespan": 128, "avg_agents_density": 0.02480602714585333, "runtime": 30.581113116815686, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-067"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 514, "makespan": 128, "avg_agents_density": 0.02722690281602214, "runtime": 30.881127884611487, "a_collisions": 39, "o_collisions": 14}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-068"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 720, "makespan": 128, "avg_agents_density": 0.03947857572782103, "runtime": 30.986598018556833, "a_collisions": 40, "o_collisions": 3}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-069"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 371, "makespan": 128, "avg_agents_density": 0.0313713997334173, "runtime": 30.237260119989514, "a_collisions": 18, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-070"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 107, "SoC": 246, "makespan": 108, "avg_agents_density": 0.039638266695773396, "runtime": 25.35705346800387, "a_collisions": 16, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-071"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 124, "makespan": 24, "avg_agents_density": 0.024681583701757607, "runtime": 5.730438280850649, "a_collisions": 5, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-072"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 166, "makespan": 45, "avg_agents_density": 0.03872141514104142, "runtime": 11.796483155339956, "a_collisions": 2, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-073"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 399, "makespan": 128, "avg_agents_density": 0.05346762059058225, "runtime": 29.581435542553663, "a_collisions": 6, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-074"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 225, "makespan": 57, "avg_agents_density": 0.027834978972867276, "runtime": 12.891658755019307, "a_collisions": 21, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-075"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 306, "makespan": 128, "avg_agents_density": 0.035612078118860815, "runtime": 31.1238413490355, "a_collisions": 0, "o_collisions": 2}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-076"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 162, "makespan": 24, "avg_agents_density": 0.033963205851824246, "runtime": 5.506029076874256, "a_collisions": 13, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-077"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 139, "makespan": 24, "avg_agents_density": 0.03411814945285484, "runtime": 5.491460088640451, "a_collisions": 1, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-078"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 223, "makespan": 128, "avg_agents_density": 0.030240670847849687, "runtime": 29.737675851210952, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-079"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 127, "makespan": 21, "avg_agents_density": 0.021438274234971688, "runtime": 5.263666737824678, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-080"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 256, "makespan": 128, "avg_agents_density": 0.029455285253695434, "runtime": 29.877605114132166, "a_collisions": 19, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-081"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 436, "makespan": 128, "avg_agents_density": 0.027393097376444058, "runtime": 29.628716744482517, "a_collisions": 4, "o_collisions": 15}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-082"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 104, "makespan": 30, "avg_agents_density": 0.019067538171809416, "runtime": 7.12320545129478, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-083"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 455, "makespan": 128, "avg_agents_density": 0.03404536592964554, "runtime": 31.121266692876816, "a_collisions": 17, "o_collisions": 6}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-084"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 473, "makespan": 128, "avg_agents_density": 0.03524862128730398, "runtime": 30.66800538264215, "a_collisions": 12, "o_collisions": 2}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-085"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 150, "makespan": 33, "avg_agents_density": 0.03288179127806376, "runtime": 7.6299586948007345, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-086"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 368, "makespan": 128, "avg_agents_density": 0.02345287937705964, "runtime": 31.433484280481935, "a_collisions": 18, "o_collisions": 4}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-087"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 151, "makespan": 51, "avg_agents_density": 0.027390292602860314, "runtime": 11.91054717078805, "a_collisions": 4, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-088"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 145, "makespan": 26, "avg_agents_density": 0.031681272382566565, "runtime": 6.124231588095427, "a_collisions": 4, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-089"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 232, "makespan": 65, "avg_agents_density": 0.034113123831562134, "runtime": 16.44173107855022, "a_collisions": 19, "o_collisions": 4}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-090"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 177, "makespan": 60, "avg_agents_density": 0.043779892885463245, "runtime": 14.353890378028154, "a_collisions": 17, "o_collisions": 3}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-091"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 467, "makespan": 128, "avg_agents_density": 0.030297178452662766, "runtime": 30.17193688824773, "a_collisions": 5, "o_collisions": 27}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-092"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 249, "makespan": 128, "avg_agents_density": 0.03896882733957228, "runtime": 31.8018763884902, "a_collisions": 0, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-093"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 219, "makespan": 37, "avg_agents_density": 0.04077881569339707, "runtime": 8.737700255587697, "a_collisions": 29, "o_collisions": 5}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-094"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 453, "makespan": 128, "avg_agents_density": 0.03250577799235334, "runtime": 29.712928365916014, "a_collisions": 27, "o_collisions": 10}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-095"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 154, "makespan": 28, "avg_agents_density": 0.03327789698615177, "runtime": 6.727163288742304, "a_collisions": 3, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-096"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 149, "makespan": 34, "avg_agents_density": 0.030429192184083898, "runtime": 8.258214415982366, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-097"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 325, "makespan": 128, "avg_agents_density": 0.027545078193387074, "runtime": 30.369123835116625, "a_collisions": 19, "o_collisions": 12}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-098"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 255, "makespan": 128, "avg_agents_density": 0.03617857979096351, "runtime": 29.899450106546283, "a_collisions": 1, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-099"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 139, "makespan": 22, "avg_agents_density": 0.041022189058598425, "runtime": 5.252278024330735, "a_collisions": 3, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-100"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 176, "makespan": 44, "avg_agents_density": 0.026828503378763052, "runtime": 10.099063031375408, "a_collisions": 9, "o_collisions": 2}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-101"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 175, "makespan": 40, "avg_agents_density": 0.028575219957716114, "runtime": 9.338623821735382, "a_collisions": 7, "o_collisions": 2}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-102"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 120, "makespan": 22, "avg_agents_density": 0.03003982625229954, "runtime": 5.396676702424884, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-103"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 355, "makespan": 128, "avg_agents_density": 0.03974533190264077, "runtime": 29.30083599872887, "a_collisions": 120, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-104"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 455, "makespan": 128, "avg_agents_density": 0.027703751784496244, "runtime": 30.301148232072592, "a_collisions": 16, "o_collisions": 4}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-105"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 134, "makespan": 24, "avg_agents_density": 0.028269001458984814, "runtime": 5.692323377355933, "a_collisions": 1, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-106"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 218, "makespan": 92, "avg_agents_density": 0.03157611937618194, "runtime": 21.292848439887166, "a_collisions": 37, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-107"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 399, "makespan": 128, "avg_agents_density": 0.028793904974122757, "runtime": 29.578811693936586, "a_collisions": 8, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-108"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 313, "makespan": 128, "avg_agents_density": 0.03045073224497672, "runtime": 30.515573870390654, "a_collisions": 5, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-109"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 413, "makespan": 128, "avg_agents_density": 0.03448638889925045, "runtime": 30.45256415940821, "a_collisions": 14, "o_collisions": 5}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-110"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 127, "makespan": 25, "avg_agents_density": 0.033174148688773206, "runtime": 5.828195545822382, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-111"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 172, "makespan": 33, "avg_agents_density": 0.03225795637346491, "runtime": 7.660146091133356, "a_collisions": 2, "o_collisions": 3}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-112"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 157, "makespan": 28, "avg_agents_density": 0.02717600128671824, "runtime": 6.862426020205021, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-113"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 261, "makespan": 128, "avg_agents_density": 0.03013038959855296, "runtime": 30.88772714138031, "a_collisions": 3, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-114"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 276, "makespan": 128, "avg_agents_density": 0.03716328147991907, "runtime": 30.204786153510213, "a_collisions": 5, "o_collisions": 2}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-115"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 174, "makespan": 38, "avg_agents_density": 0.033058250262054834, "runtime": 9.426432279869914, "a_collisions": 5, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-116"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 235, "makespan": 128, "avg_agents_density": 0.023771968156609372, "runtime": 31.07422902621329, "a_collisions": 12, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-117"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 154, "makespan": 40, "avg_agents_density": 0.02930699394616118, "runtime": 9.694709084928036, "a_collisions": 3, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-118"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 353, "makespan": 128, "avg_agents_density": 0.035971568163999816, "runtime": 28.75333970040083, "a_collisions": 17, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-119"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 132, "makespan": 28, "avg_agents_density": 0.022065302768154726, "runtime": 7.141558725386858, "a_collisions": 1, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-120"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 546, "makespan": 128, "avg_agents_density": 0.04330348936740936, "runtime": 30.78249901533127, "a_collisions": 52, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-121"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 161, "makespan": 36, "avg_agents_density": 0.02535268121536644, "runtime": 8.438319951295853, "a_collisions": 9, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-122"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 133, "makespan": 27, "avg_agents_density": 0.027004068774421474, "runtime": 6.433684777468443, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-123"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 526, "makespan": 128, "avg_agents_density": 0.02929061917716678, "runtime": 31.068842576816678, "a_collisions": 22, "o_collisions": 9}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-124"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 248, "makespan": 128, "avg_agents_density": 0.03398097235780889, "runtime": 29.974173303693533, "a_collisions": 0, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-125"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 542, "makespan": 128, "avg_agents_density": 0.03314899983452801, "runtime": 30.26653372310102, "a_collisions": 49, "o_collisions": 1}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-126"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 125, "makespan": 24, "avg_agents_density": 0.028082689551409374, "runtime": 5.979770367965102, "a_collisions": 10, "o_collisions": 0}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-127"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 679, "makespan": 128, "avg_agents_density": 0.048328518845897644, "runtime": 30.684587616473436, "a_collisions": 73, "o_collisions": 8}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1153, "makespan": 128, "avg_agents_density": 0.04889487152020715, "runtime": 31.175074407830834, "a_collisions": 59, "o_collisions": 52}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 872, "makespan": 128, "avg_agents_density": 0.043412241442370596, "runtime": 31.22699910402298, "a_collisions": 67, "o_collisions": 4}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 540, "makespan": 128, "avg_agents_density": 0.06311000167834609, "runtime": 30.564092153683305, "a_collisions": 24, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 944, "makespan": 128, "avg_agents_density": 0.0503056648068393, "runtime": 31.22196306474507, "a_collisions": 85, "o_collisions": 7}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 974, "makespan": 128, "avg_agents_density": 0.05420786033930406, "runtime": 31.67049435339868, "a_collisions": 71, "o_collisions": 37}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 853, "makespan": 128, "avg_agents_density": 0.04195883948765731, "runtime": 31.249455908313394, "a_collisions": 24, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 1175, "makespan": 128, "avg_agents_density": 0.046013014631000194, "runtime": 31.56019390746951, "a_collisions": 172, "o_collisions": 40}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 898, "makespan": 128, "avg_agents_density": 0.07299255687888892, "runtime": 31.000712234526873, "a_collisions": 38, "o_collisions": 9}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 747, "makespan": 128, "avg_agents_density": 0.050330985007538145, "runtime": 31.116534013301134, "a_collisions": 5, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 755, "makespan": 128, "avg_agents_density": 0.04213760146466492, "runtime": 30.96361345797777, "a_collisions": 49, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 948, "makespan": 128, "avg_agents_density": 0.08479437323713791, "runtime": 31.159191697835922, "a_collisions": 51, "o_collisions": 8}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 755, "makespan": 128, "avg_agents_density": 0.053240377159046816, "runtime": 30.761831026524305, "a_collisions": 68, "o_collisions": 9}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 383, "makespan": 128, "avg_agents_density": 0.05717976806481877, "runtime": 31.58005741238594, "a_collisions": 5, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 924, "makespan": 128, "avg_agents_density": 0.08083835052502629, "runtime": 30.8872590996325, "a_collisions": 95, "o_collisions": 32}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 957, "makespan": 128, "avg_agents_density": 0.04398998254893912, "runtime": 30.42775747925043, "a_collisions": 44, "o_collisions": 6}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 661, "makespan": 128, "avg_agents_density": 0.05499508694814568, "runtime": 31.262115590274334, "a_collisions": 59, "o_collisions": 15}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 643, "makespan": 128, "avg_agents_density": 0.04826131538977296, "runtime": 31.999794341623783, "a_collisions": 34, "o_collisions": 79}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1252, "makespan": 128, "avg_agents_density": 0.06349397521036314, "runtime": 31.493184303864837, "a_collisions": 102, "o_collisions": 51}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 831, "makespan": 128, "avg_agents_density": 0.07064489762906821, "runtime": 31.98993058875203, "a_collisions": 102, "o_collisions": 32}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 1004, "makespan": 128, "avg_agents_density": 0.05375137798125365, "runtime": 30.822388753294945, "a_collisions": 118, "o_collisions": 11}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 1050, "makespan": 128, "avg_agents_density": 0.060135438625208835, "runtime": 30.979306034743786, "a_collisions": 61, "o_collisions": 55}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 928, "makespan": 128, "avg_agents_density": 0.05112509661120897, "runtime": 31.99577931687236, "a_collisions": 19, "o_collisions": 4}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 836, "makespan": 128, "avg_agents_density": 0.055035210615174905, "runtime": 30.706038219854236, "a_collisions": 43, "o_collisions": 5}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 707, "makespan": 128, "avg_agents_density": 0.05994072351216673, "runtime": 31.36768965050578, "a_collisions": 55, "o_collisions": 1}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 300, "makespan": 29, "avg_agents_density": 0.04287680611580109, "runtime": 6.927042992785573, "a_collisions": 3, "o_collisions": 9}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 662, "makespan": 128, "avg_agents_density": 0.042110815395572744, "runtime": 31.507304782047868, "a_collisions": 41, "o_collisions": 8}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 789, "makespan": 128, "avg_agents_density": 0.05239076975954846, "runtime": 31.607752706855536, "a_collisions": 8, "o_collisions": 2}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 518, "makespan": 76, "avg_agents_density": 0.04835103910155779, "runtime": 18.307494968175888, "a_collisions": 50, "o_collisions": 10}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 779, "makespan": 128, "avg_agents_density": 0.0423574615741281, "runtime": 31.065790977329016, "a_collisions": 36, "o_collisions": 42}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 710, "makespan": 128, "avg_agents_density": 0.05930815326242892, "runtime": 31.09176892787218, "a_collisions": 48, "o_collisions": 26}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 323, "makespan": 32, "avg_agents_density": 0.055045516504427516, "runtime": 7.724889187142253, "a_collisions": 5, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 121, "SoC": 588, "makespan": 122, "avg_agents_density": 0.04596916563051907, "runtime": 29.470403717830777, "a_collisions": 4, "o_collisions": 1}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-032"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 1112, "makespan": 128, "avg_agents_density": 0.06104465817198554, "runtime": 32.11016158014536, "a_collisions": 88, "o_collisions": 6}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-033"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 777, "makespan": 128, "avg_agents_density": 0.08514570275211975, "runtime": 30.14364622347057, "a_collisions": 64, "o_collisions": 2}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-034"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 809, "makespan": 128, "avg_agents_density": 0.04943186880896144, "runtime": 31.568084504455328, "a_collisions": 36, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-035"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 908, "makespan": 128, "avg_agents_density": 0.05764165791427695, "runtime": 30.93544454500079, "a_collisions": 186, "o_collisions": 11}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-036"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1166, "makespan": 128, "avg_agents_density": 0.0723002902719006, "runtime": 30.417480174452066, "a_collisions": 104, "o_collisions": 12}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-037"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 611, "makespan": 128, "avg_agents_density": 0.06236044582258636, "runtime": 30.639816427603364, "a_collisions": 20, "o_collisions": 1}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-038"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 1082, "makespan": 128, "avg_agents_density": 0.06100549780143116, "runtime": 30.844029899686575, "a_collisions": 77, "o_collisions": 34}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-039"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 1082, "makespan": 128, "avg_agents_density": 0.05541825762908973, "runtime": 30.560595270246267, "a_collisions": 114, "o_collisions": 24}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-040"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 1176, "makespan": 128, "avg_agents_density": 0.059514060273241666, "runtime": 31.89805717766285, "a_collisions": 199, "o_collisions": 70}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-041"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 770, "makespan": 128, "avg_agents_density": 0.06492623929106574, "runtime": 32.05142912454903, "a_collisions": 63, "o_collisions": 14}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-042"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 439, "makespan": 82, "avg_agents_density": 0.031744216692653315, "runtime": 19.46671638265252, "a_collisions": 7, "o_collisions": 1}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-043"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 861, "makespan": 128, "avg_agents_density": 0.05037038052754398, "runtime": 30.775016652420163, "a_collisions": 15, "o_collisions": 2}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-044"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 841, "makespan": 128, "avg_agents_density": 0.057101803578528114, "runtime": 31.612215826287866, "a_collisions": 50, "o_collisions": 14}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-045"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 797, "makespan": 128, "avg_agents_density": 0.04690759035645569, "runtime": 31.805896278470755, "a_collisions": 21, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-046"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 919, "makespan": 128, "avg_agents_density": 0.06491165399037295, "runtime": 31.01053856872022, "a_collisions": 118, "o_collisions": 51}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-047"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 940, "makespan": 128, "avg_agents_density": 0.05557912318154498, "runtime": 31.185521598905325, "a_collisions": 52, "o_collisions": 9}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-048"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1131, "makespan": 128, "avg_agents_density": 0.07538358260584284, "runtime": 33.048847544938326, "a_collisions": 28, "o_collisions": 1}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-049"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 1020, "makespan": 128, "avg_agents_density": 0.0700977221087387, "runtime": 30.243453605100513, "a_collisions": 56, "o_collisions": 62}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-050"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 898, "makespan": 128, "avg_agents_density": 0.047085144702776964, "runtime": 32.73742323741317, "a_collisions": 14, "o_collisions": 2}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-051"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 127, "SoC": 1134, "makespan": 128, "avg_agents_density": 0.04730457360883853, "runtime": 31.64874941110611, "a_collisions": 42, "o_collisions": 21}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-052"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 127, "SoC": 1337, "makespan": 128, "avg_agents_density": 0.07683732687661024, "runtime": 32.7172767855227, "a_collisions": 146, "o_collisions": 56}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-053"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 734, "makespan": 128, "avg_agents_density": 0.05456933592481952, "runtime": 31.555621422827244, "a_collisions": 169, "o_collisions": 5}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-054"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 1025, "makespan": 128, "avg_agents_density": 0.05241659270062203, "runtime": 30.690370433032513, "a_collisions": 75, "o_collisions": 6}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-055"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 837, "makespan": 128, "avg_agents_density": 0.0382070516802812, "runtime": 31.373497480526567, "a_collisions": 144, "o_collisions": 50}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-056"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 904, "makespan": 128, "avg_agents_density": 0.05832990195062932, "runtime": 32.133886652067304, "a_collisions": 98, "o_collisions": 15}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-057"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 127, "SoC": 1210, "makespan": 128, "avg_agents_density": 0.08252939464922696, "runtime": 32.038674496114254, "a_collisions": 111, "o_collisions": 44}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-058"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1212, "makespan": 128, "avg_agents_density": 0.0539503521412804, "runtime": 30.834506837651134, "a_collisions": 123, "o_collisions": 40}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-059"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 683, "makespan": 128, "avg_agents_density": 0.04447605284202808, "runtime": 31.217584749683738, "a_collisions": 10, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-060"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 740, "makespan": 128, "avg_agents_density": 0.05208232730152398, "runtime": 31.200714515522122, "a_collisions": 108, "o_collisions": 12}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-061"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 1076, "makespan": 128, "avg_agents_density": 0.044341426062177294, "runtime": 31.10958605632186, "a_collisions": 138, "o_collisions": 8}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-062"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 1040, "makespan": 128, "avg_agents_density": 0.06684405977286582, "runtime": 30.303545009344816, "a_collisions": 103, "o_collisions": 13}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-063"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 904, "makespan": 128, "avg_agents_density": 0.06608067383481095, "runtime": 31.151438862085342, "a_collisions": 25, "o_collisions": 27}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-064"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 963, "makespan": 128, "avg_agents_density": 0.07159926133254847, "runtime": 30.63933413848281, "a_collisions": 165, "o_collisions": 4}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-065"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 956, "makespan": 128, "avg_agents_density": 0.05215722685962525, "runtime": 30.025360172614455, "a_collisions": 161, "o_collisions": 2}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-066"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 861, "makespan": 128, "avg_agents_density": 0.04156164956302081, "runtime": 31.081940062344074, "a_collisions": 2, "o_collisions": 3}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-067"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 524, "makespan": 81, "avg_agents_density": 0.046961605260727374, "runtime": 19.654188349843025, "a_collisions": 67, "o_collisions": 62}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-068"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 1343, "makespan": 128, "avg_agents_density": 0.06897214472393061, "runtime": 30.851951954886317, "a_collisions": 88, "o_collisions": 7}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-069"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 1019, "makespan": 128, "avg_agents_density": 0.0681842039923687, "runtime": 30.474330766126513, "a_collisions": 113, "o_collisions": 24}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-070"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 932, "makespan": 128, "avg_agents_density": 0.05037941702051218, "runtime": 30.652995875105262, "a_collisions": 92, "o_collisions": 13}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-071"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 528, "makespan": 128, "avg_agents_density": 0.02605763459936081, "runtime": 30.11079858057201, "a_collisions": 10, "o_collisions": 61}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-072"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 792, "makespan": 128, "avg_agents_density": 0.0666098591240359, "runtime": 30.442283321172, "a_collisions": 57, "o_collisions": 6}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-073"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 1039, "makespan": 128, "avg_agents_density": 0.09086079289663222, "runtime": 28.67951769568026, "a_collisions": 191, "o_collisions": 35}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-074"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 829, "makespan": 128, "avg_agents_density": 0.0419233966324373, "runtime": 30.186503052711487, "a_collisions": 5, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-075"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 1105, "makespan": 128, "avg_agents_density": 0.055898730288318425, "runtime": 30.70015048608184, "a_collisions": 91, "o_collisions": 20}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-076"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 849, "makespan": 128, "avg_agents_density": 0.054655747642905365, "runtime": 30.00457688048482, "a_collisions": 36, "o_collisions": 4}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-077"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 789, "makespan": 128, "avg_agents_density": 0.06098099531827183, "runtime": 31.00976819731295, "a_collisions": 38, "o_collisions": 7}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-078"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 277, "makespan": 29, "avg_agents_density": 0.04550645583229878, "runtime": 7.490962654352188, "a_collisions": 2, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-079"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 371, "makespan": 46, "avg_agents_density": 0.0456359589028245, "runtime": 10.548292886465788, "a_collisions": 3, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-080"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 878, "makespan": 128, "avg_agents_density": 0.061264273814795316, "runtime": 31.090836750343442, "a_collisions": 50, "o_collisions": 3}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-081"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 853, "makespan": 128, "avg_agents_density": 0.048648625095320204, "runtime": 29.984020641073585, "a_collisions": 39, "o_collisions": 12}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-082"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 512, "makespan": 128, "avg_agents_density": 0.040600056594761916, "runtime": 31.071680936962366, "a_collisions": 5, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-083"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 826, "makespan": 128, "avg_agents_density": 0.05658653897880179, "runtime": 30.8958259280771, "a_collisions": 131, "o_collisions": 38}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-084"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 896, "makespan": 128, "avg_agents_density": 0.0607315617676748, "runtime": 29.855821983888745, "a_collisions": 66, "o_collisions": 35}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-085"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 761, "makespan": 128, "avg_agents_density": 0.050561189054766024, "runtime": 30.96280960738659, "a_collisions": 13, "o_collisions": 16}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-086"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 977, "makespan": 128, "avg_agents_density": 0.06621691835308473, "runtime": 30.94625467248261, "a_collisions": 37, "o_collisions": 3}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-087"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 1055, "makespan": 128, "avg_agents_density": 0.04746242454629316, "runtime": 30.470795325934887, "a_collisions": 114, "o_collisions": 22}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-088"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 903, "makespan": 128, "avg_agents_density": 0.05105427594964807, "runtime": 30.949509417638183, "a_collisions": 57, "o_collisions": 6}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-089"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 977, "makespan": 128, "avg_agents_density": 0.06333012434072391, "runtime": 31.481272663921118, "a_collisions": 48, "o_collisions": 8}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-090"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 836, "makespan": 128, "avg_agents_density": 0.0648710875747833, "runtime": 31.143574576824903, "a_collisions": 78, "o_collisions": 18}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-091"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 635, "makespan": 128, "avg_agents_density": 0.04164651000604613, "runtime": 29.20127715729177, "a_collisions": 14, "o_collisions": 109}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-092"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 677, "makespan": 128, "avg_agents_density": 0.053716595762955975, "runtime": 31.305181512609124, "a_collisions": 175, "o_collisions": 18}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-093"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 860, "makespan": 128, "avg_agents_density": 0.06271858403736397, "runtime": 31.51487767510116, "a_collisions": 186, "o_collisions": 69}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-094"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 939, "makespan": 128, "avg_agents_density": 0.04467190084265752, "runtime": 30.266200417652726, "a_collisions": 33, "o_collisions": 8}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-095"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 868, "makespan": 128, "avg_agents_density": 0.050740973185209, "runtime": 31.117143373936415, "a_collisions": 42, "o_collisions": 14}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-096"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 1165, "makespan": 128, "avg_agents_density": 0.04404061466322938, "runtime": 30.756655795499682, "a_collisions": 52, "o_collisions": 5}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-097"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 1036, "makespan": 128, "avg_agents_density": 0.05282158707568645, "runtime": 30.253577426075935, "a_collisions": 84, "o_collisions": 98}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-098"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 1215, "makespan": 128, "avg_agents_density": 0.062134878835047015, "runtime": 31.195244200527668, "a_collisions": 66, "o_collisions": 9}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-099"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 729, "makespan": 128, "avg_agents_density": 0.05036102746152813, "runtime": 30.687387673184276, "a_collisions": 47, "o_collisions": 5}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-100"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 735, "makespan": 128, "avg_agents_density": 0.047048934139047906, "runtime": 30.624535949900746, "a_collisions": 25, "o_collisions": 17}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-101"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 1012, "makespan": 128, "avg_agents_density": 0.05448427165856283, "runtime": 30.421705074608326, "a_collisions": 38, "o_collisions": 7}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-102"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 337, "makespan": 61, "avg_agents_density": 0.05501768565221216, "runtime": 14.571415076032281, "a_collisions": 6, "o_collisions": 1}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-103"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 924, "makespan": 128, "avg_agents_density": 0.05282900547328239, "runtime": 30.23614927008748, "a_collisions": 117, "o_collisions": 1}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-104"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 1039, "makespan": 128, "avg_agents_density": 0.04530641255369153, "runtime": 33.39350832812488, "a_collisions": 102, "o_collisions": 34}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-105"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 784, "makespan": 128, "avg_agents_density": 0.04200431259069456, "runtime": 33.419033750891685, "a_collisions": 19, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-106"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 127, "SoC": 1168, "makespan": 128, "avg_agents_density": 0.0655822452963502, "runtime": 31.220422187820077, "a_collisions": 121, "o_collisions": 2}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-107"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 761, "makespan": 128, "avg_agents_density": 0.060148288730783386, "runtime": 31.758972514420748, "a_collisions": 44, "o_collisions": 5}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-108"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 890, "makespan": 128, "avg_agents_density": 0.053432685332422944, "runtime": 32.24121765419841, "a_collisions": 54, "o_collisions": 9}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-109"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 1001, "makespan": 128, "avg_agents_density": 0.06717746311212015, "runtime": 31.405455101281404, "a_collisions": 18, "o_collisions": 21}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-110"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 665, "makespan": 128, "avg_agents_density": 0.055486768502418064, "runtime": 32.05135647393763, "a_collisions": 25, "o_collisions": 6}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-111"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 1741, "makespan": 128, "avg_agents_density": 0.08489401777436605, "runtime": 32.245361959561706, "a_collisions": 247, "o_collisions": 31}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-112"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 620, "makespan": 128, "avg_agents_density": 0.048974718137577394, "runtime": 30.64349837973714, "a_collisions": 18, "o_collisions": 2}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-113"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 723, "makespan": 128, "avg_agents_density": 0.04694043839775252, "runtime": 30.896316865459085, "a_collisions": 15, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-114"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 853, "makespan": 128, "avg_agents_density": 0.06896878635440105, "runtime": 30.669835595414042, "a_collisions": 26, "o_collisions": 7}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-115"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 683, "makespan": 128, "avg_agents_density": 0.05436598144537461, "runtime": 30.593845872208476, "a_collisions": 15, "o_collisions": 8}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-116"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 627, "makespan": 128, "avg_agents_density": 0.04081770408242814, "runtime": 30.97324519790709, "a_collisions": 17, "o_collisions": 2}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-117"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 950, "makespan": 128, "avg_agents_density": 0.044375690355974724, "runtime": 31.56174698844552, "a_collisions": 17, "o_collisions": 6}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-118"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 755, "makespan": 128, "avg_agents_density": 0.05539805154166969, "runtime": 30.130164677277207, "a_collisions": 47, "o_collisions": 12}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-119"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 613, "makespan": 128, "avg_agents_density": 0.03532099380585838, "runtime": 31.23947329260409, "a_collisions": 4, "o_collisions": 1}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-120"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 1032, "makespan": 128, "avg_agents_density": 0.053777080575664174, "runtime": 31.296245018020272, "a_collisions": 67, "o_collisions": 19}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-121"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 907, "makespan": 128, "avg_agents_density": 0.0418606542401432, "runtime": 29.761314529925585, "a_collisions": 75, "o_collisions": 3}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-122"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 582, "makespan": 128, "avg_agents_density": 0.04318177057144302, "runtime": 30.327567510306835, "a_collisions": 8, "o_collisions": 1}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-123"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 127, "SoC": 1254, "makespan": 128, "avg_agents_density": 0.06100497339050312, "runtime": 30.962586062029004, "a_collisions": 155, "o_collisions": 20}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-124"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 807, "makespan": 128, "avg_agents_density": 0.04835376440494297, "runtime": 30.787116395309567, "a_collisions": 17, "o_collisions": 34}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-125"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 1175, "makespan": 128, "avg_agents_density": 0.0711223285363302, "runtime": 30.55386464484036, "a_collisions": 118, "o_collisions": 46}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-126"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 533, "makespan": 128, "avg_agents_density": 0.041724282037882594, "runtime": 31.42512482404709, "a_collisions": 40, "o_collisions": 0}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-127"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2089, "makespan": 128, "avg_agents_density": 0.0660441480225795, "runtime": 32.06942865997553, "a_collisions": 91, "o_collisions": 73}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2286, "makespan": 128, "avg_agents_density": 0.0888247556230165, "runtime": 31.860279832035303, "a_collisions": 180, "o_collisions": 167}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1855, "makespan": 128, "avg_agents_density": 0.06621333193750831, "runtime": 31.043089482933283, "a_collisions": 165, "o_collisions": 242}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1540, "makespan": 128, "avg_agents_density": 0.07630827414974435, "runtime": 32.775912806391716, "a_collisions": 97, "o_collisions": 175}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1919, "makespan": 128, "avg_agents_density": 0.07515041331549167, "runtime": 30.841061355546117, "a_collisions": 184, "o_collisions": 149}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2288, "makespan": 128, "avg_agents_density": 0.07942064973872127, "runtime": 31.567322267219424, "a_collisions": 361, "o_collisions": 179}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1729, "makespan": 128, "avg_agents_density": 0.07057299746228332, "runtime": 31.22336906194687, "a_collisions": 117, "o_collisions": 263}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2287, "makespan": 128, "avg_agents_density": 0.07971534305104457, "runtime": 31.29482347331941, "a_collisions": 346, "o_collisions": 254}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1983, "makespan": 128, "avg_agents_density": 0.07508752372432613, "runtime": 30.60191022604704, "a_collisions": 140, "o_collisions": 152}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1579, "makespan": 128, "avg_agents_density": 0.08035655136660175, "runtime": 31.930721901357174, "a_collisions": 134, "o_collisions": 158}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1838, "makespan": 128, "avg_agents_density": 0.057499269818040245, "runtime": 31.306608563289046, "a_collisions": 138, "o_collisions": 200}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2058, "makespan": 128, "avg_agents_density": 0.1240449634924891, "runtime": 31.08939821831882, "a_collisions": 310, "o_collisions": 183}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1777, "makespan": 128, "avg_agents_density": 0.06746832364921276, "runtime": 31.685078414157033, "a_collisions": 170, "o_collisions": 147}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1637, "makespan": 128, "avg_agents_density": 0.07557294077198949, "runtime": 31.443003688007593, "a_collisions": 74, "o_collisions": 189}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1640, "makespan": 128, "avg_agents_density": 0.08711056115568211, "runtime": 30.78360665589571, "a_collisions": 148, "o_collisions": 93}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 1552, "makespan": 128, "avg_agents_density": 0.07458423431689594, "runtime": 32.14802796393633, "a_collisions": 98, "o_collisions": 113}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1619, "makespan": 128, "avg_agents_density": 0.07594788690787543, "runtime": 31.65220977179706, "a_collisions": 183, "o_collisions": 216}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1572, "makespan": 128, "avg_agents_density": 0.054602473520199514, "runtime": 30.528815746307373, "a_collisions": 41, "o_collisions": 187}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 2196, "makespan": 128, "avg_agents_density": 0.08643396222058321, "runtime": 32.72420366294682, "a_collisions": 209, "o_collisions": 155}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 2205, "makespan": 128, "avg_agents_density": 0.07428078094013499, "runtime": 31.225441493093967, "a_collisions": 396, "o_collisions": 198}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2026, "makespan": 128, "avg_agents_density": 0.06877618822096618, "runtime": 30.404729191213846, "a_collisions": 355, "o_collisions": 268}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1948, "makespan": 128, "avg_agents_density": 0.08164255081343987, "runtime": 32.227804001420736, "a_collisions": 205, "o_collisions": 95}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 2138, "makespan": 128, "avg_agents_density": 0.07402834762019578, "runtime": 30.879769396036863, "a_collisions": 170, "o_collisions": 241}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 2018, "makespan": 128, "avg_agents_density": 0.08595242927617754, "runtime": 31.335199415683746, "a_collisions": 153, "o_collisions": 130}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2023, "makespan": 128, "avg_agents_density": 0.07727737384913648, "runtime": 31.856363790109754, "a_collisions": 314, "o_collisions": 167}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1619, "makespan": 128, "avg_agents_density": 0.05762424849219623, "runtime": 31.2122057788074, "a_collisions": 57, "o_collisions": 459}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1578, "makespan": 128, "avg_agents_density": 0.06707548352649646, "runtime": 30.986424922943115, "a_collisions": 141, "o_collisions": 268}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1849, "makespan": 128, "avg_agents_density": 0.0680784984880096, "runtime": 32.25648953393102, "a_collisions": 82, "o_collisions": 195}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1776, "makespan": 128, "avg_agents_density": 0.0677787643896744, "runtime": 31.47823433019221, "a_collisions": 199, "o_collisions": 146}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1572, "makespan": 128, "avg_agents_density": 0.07890512965575626, "runtime": 31.464036175981164, "a_collisions": 151, "o_collisions": 183}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1979, "makespan": 128, "avg_agents_density": 0.08383375116575123, "runtime": 31.372916674241424, "a_collisions": 416, "o_collisions": 49}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1558, "makespan": 128, "avg_agents_density": 0.06670113130947265, "runtime": 32.79014832340181, "a_collisions": 153, "o_collisions": 401}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1650, "makespan": 128, "avg_agents_density": 0.08353118665534591, "runtime": 32.24533631466329, "a_collisions": 193, "o_collisions": 276}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-032"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4166666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 2581, "makespan": 128, "avg_agents_density": 0.08596045640198506, "runtime": 31.196218686178327, "a_collisions": 322, "o_collisions": 344}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-033"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.8333333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1633, "makespan": 128, "avg_agents_density": 0.11958352815443136, "runtime": 31.84931703656912, "a_collisions": 198, "o_collisions": 156}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-034"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 2120, "makespan": 128, "avg_agents_density": 0.08943871967520643, "runtime": 31.308580797165632, "a_collisions": 147, "o_collisions": 86}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-035"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2154, "makespan": 128, "avg_agents_density": 0.0979108786602987, "runtime": 31.72232387214899, "a_collisions": 109, "o_collisions": 81}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-036"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1897, "makespan": 128, "avg_agents_density": 0.08187243821330367, "runtime": 30.42868191562593, "a_collisions": 216, "o_collisions": 309}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-037"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1712, "makespan": 128, "avg_agents_density": 0.0657357270329067, "runtime": 31.63147297501564, "a_collisions": 120, "o_collisions": 255}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-038"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2357, "makespan": 128, "avg_agents_density": 0.09376637802039697, "runtime": 31.326485753059387, "a_collisions": 319, "o_collisions": 44}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-039"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 2073, "makespan": 128, "avg_agents_density": 0.08293832552960388, "runtime": 31.81142470613122, "a_collisions": 432, "o_collisions": 158}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-040"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4166666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 2254, "makespan": 128, "avg_agents_density": 0.08813395479254003, "runtime": 31.47047475166619, "a_collisions": 315, "o_collisions": 315}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-041"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1885, "makespan": 128, "avg_agents_density": 0.07805699032519225, "runtime": 31.45164823718369, "a_collisions": 152, "o_collisions": 101}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-042"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1590, "makespan": 128, "avg_agents_density": 0.050317016032184816, "runtime": 31.12826824374497, "a_collisions": 59, "o_collisions": 271}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-043"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1375, "makespan": 128, "avg_agents_density": 0.08372422132390925, "runtime": 32.11197745986283, "a_collisions": 57, "o_collisions": 48}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-044"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1999, "makespan": 128, "avg_agents_density": 0.07620251685965491, "runtime": 30.85593396052718, "a_collisions": 175, "o_collisions": 134}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-045"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1747, "makespan": 128, "avg_agents_density": 0.059836568520854075, "runtime": 31.507682543247938, "a_collisions": 31, "o_collisions": 264}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-046"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4166666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 2224, "makespan": 128, "avg_agents_density": 0.07913829352551338, "runtime": 31.535746520385146, "a_collisions": 305, "o_collisions": 217}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-047"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1733, "makespan": 128, "avg_agents_density": 0.07492525632478018, "runtime": 31.078724209219217, "a_collisions": 111, "o_collisions": 208}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-048"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2269, "makespan": 128, "avg_agents_density": 0.07768695041483643, "runtime": 31.47736538760364, "a_collisions": 181, "o_collisions": 146}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-049"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1949, "makespan": 128, "avg_agents_density": 0.09318572461337594, "runtime": 31.856945337727666, "a_collisions": 310, "o_collisions": 168}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-050"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 1925, "makespan": 128, "avg_agents_density": 0.0702154363191071, "runtime": 31.92199045047164, "a_collisions": 143, "o_collisions": 155}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-051"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 1992, "makespan": 128, "avg_agents_density": 0.06309397127064809, "runtime": 32.04219931550324, "a_collisions": 148, "o_collisions": 151}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-052"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 2628, "makespan": 128, "avg_agents_density": 0.12410603263340166, "runtime": 31.923551935702562, "a_collisions": 493, "o_collisions": 261}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-053"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1921, "makespan": 128, "avg_agents_density": 0.08124608370408437, "runtime": 31.22073733434081, "a_collisions": 276, "o_collisions": 158}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-054"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1584, "makespan": 128, "avg_agents_density": 0.06588774276988062, "runtime": 31.1800451092422, "a_collisions": 276, "o_collisions": 266}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-055"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1922, "makespan": 128, "avg_agents_density": 0.05590649254944471, "runtime": 31.075155790895224, "a_collisions": 164, "o_collisions": 153}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-056"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1821, "makespan": 128, "avg_agents_density": 0.07798265987312154, "runtime": 31.216029919683933, "a_collisions": 120, "o_collisions": 131}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-057"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2308, "makespan": 128, "avg_agents_density": 0.08031368663147806, "runtime": 31.470655404031277, "a_collisions": 507, "o_collisions": 246}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-058"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2278, "makespan": 128, "avg_agents_density": 0.07784111908157348, "runtime": 32.17636695317924, "a_collisions": 121, "o_collisions": 189}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-059"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1864, "makespan": 128, "avg_agents_density": 0.06109833468218934, "runtime": 30.575147788971663, "a_collisions": 39, "o_collisions": 120}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-060"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1847, "makespan": 128, "avg_agents_density": 0.08490630429683584, "runtime": 32.2144062127918, "a_collisions": 329, "o_collisions": 209}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-061"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2234, "makespan": 128, "avg_agents_density": 0.07601357217774805, "runtime": 31.403658563271165, "a_collisions": 340, "o_collisions": 244}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-062"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3333333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2532, "makespan": 128, "avg_agents_density": 0.08901749793317616, "runtime": 30.706787602975965, "a_collisions": 234, "o_collisions": 185}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-063"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 2102, "makespan": 128, "avg_agents_density": 0.08618908445796222, "runtime": 32.10706150904298, "a_collisions": 164, "o_collisions": 184}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-064"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2222, "makespan": 128, "avg_agents_density": 0.1052575923666309, "runtime": 31.98231235332787, "a_collisions": 278, "o_collisions": 229}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-065"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1972, "makespan": 128, "avg_agents_density": 0.060501549562929094, "runtime": 31.502447571605444, "a_collisions": 156, "o_collisions": 279}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-066"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1458, "makespan": 128, "avg_agents_density": 0.0646333665019406, "runtime": 31.589966693893075, "a_collisions": 111, "o_collisions": 91}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-067"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 2080, "makespan": 128, "avg_agents_density": 0.07557097232147302, "runtime": 32.336961986497045, "a_collisions": 142, "o_collisions": 207}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-068"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 2342, "makespan": 128, "avg_agents_density": 0.09308175880748025, "runtime": 31.68815523944795, "a_collisions": 294, "o_collisions": 120}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-069"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 2133, "makespan": 128, "avg_agents_density": 0.0851415804423239, "runtime": 31.873384909704328, "a_collisions": 336, "o_collisions": 192}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-070"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1820, "makespan": 128, "avg_agents_density": 0.07709063996095876, "runtime": 31.617012590169907, "a_collisions": 159, "o_collisions": 181}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-071"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1623, "makespan": 128, "avg_agents_density": 0.04254054751973798, "runtime": 30.91570863313973, "a_collisions": 24, "o_collisions": 529}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-072"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1881, "makespan": 128, "avg_agents_density": 0.10585354497069224, "runtime": 31.37943223118782, "a_collisions": 297, "o_collisions": 57}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-073"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4166666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 2218, "makespan": 128, "avg_agents_density": 0.0907960681552517, "runtime": 31.968427842482924, "a_collisions": 290, "o_collisions": 190}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-074"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1849, "makespan": 128, "avg_agents_density": 0.06381503005227883, "runtime": 32.01226460188627, "a_collisions": 108, "o_collisions": 156}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-075"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2269, "makespan": 128, "avg_agents_density": 0.0818252200941231, "runtime": 31.33802312426269, "a_collisions": 247, "o_collisions": 161}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-076"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2332, "makespan": 128, "avg_agents_density": 0.06716626652150959, "runtime": 31.73988812416792, "a_collisions": 297, "o_collisions": 239}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-077"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1896, "makespan": 128, "avg_agents_density": 0.07723741781534847, "runtime": 32.07259860821068, "a_collisions": 183, "o_collisions": 143}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-078"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1686, "makespan": 128, "avg_agents_density": 0.05841430526890249, "runtime": 31.27720407769084, "a_collisions": 48, "o_collisions": 438}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-079"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1518, "makespan": 128, "avg_agents_density": 0.0605131497859977, "runtime": 31.568867702037096, "a_collisions": 43, "o_collisions": 364}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-080"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 2005, "makespan": 128, "avg_agents_density": 0.07841684749969022, "runtime": 31.451223181560636, "a_collisions": 158, "o_collisions": 41}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-081"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1716, "makespan": 128, "avg_agents_density": 0.07496541567899982, "runtime": 31.31241537630558, "a_collisions": 136, "o_collisions": 145}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-082"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1548, "makespan": 128, "avg_agents_density": 0.058669390036075755, "runtime": 31.075924836099148, "a_collisions": 51, "o_collisions": 426}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-083"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2171, "makespan": 128, "avg_agents_density": 0.07895273205446321, "runtime": 30.850585505366325, "a_collisions": 289, "o_collisions": 163}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-084"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1860, "makespan": 128, "avg_agents_density": 0.103942195241586, "runtime": 31.61121690645814, "a_collisions": 329, "o_collisions": 212}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-085"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1764, "makespan": 128, "avg_agents_density": 0.05522034339136408, "runtime": 32.337839882820845, "a_collisions": 58, "o_collisions": 247}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-086"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 2243, "makespan": 128, "avg_agents_density": 0.07436684851883765, "runtime": 31.520779881626368, "a_collisions": 349, "o_collisions": 82}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-087"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3333333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2266, "makespan": 128, "avg_agents_density": 0.0685280560617576, "runtime": 32.15324811451137, "a_collisions": 308, "o_collisions": 265}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-088"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1961, "makespan": 128, "avg_agents_density": 0.06472978844890985, "runtime": 30.955353731289506, "a_collisions": 154, "o_collisions": 109}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-089"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 2210, "makespan": 128, "avg_agents_density": 0.07611572289020961, "runtime": 32.24366703256965, "a_collisions": 137, "o_collisions": 326}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-090"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2079, "makespan": 128, "avg_agents_density": 0.09507182804304312, "runtime": 32.11425199918449, "a_collisions": 147, "o_collisions": 96}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-091"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1584, "makespan": 128, "avg_agents_density": 0.061467203801537945, "runtime": 31.21648165397346, "a_collisions": 100, "o_collisions": 150}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-092"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1929, "makespan": 128, "avg_agents_density": 0.08003637635094746, "runtime": 32.182075034826994, "a_collisions": 210, "o_collisions": 207}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-093"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2045, "makespan": 128, "avg_agents_density": 0.10287112116235148, "runtime": 31.69011809490621, "a_collisions": 363, "o_collisions": 132}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-094"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1854, "makespan": 128, "avg_agents_density": 0.06641285035419921, "runtime": 30.636790428310633, "a_collisions": 211, "o_collisions": 100}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-095"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2145, "makespan": 128, "avg_agents_density": 0.07585279839470208, "runtime": 31.40431289561093, "a_collisions": 229, "o_collisions": 237}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-096"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1907, "makespan": 128, "avg_agents_density": 0.07914271781922103, "runtime": 33.10483611188829, "a_collisions": 153, "o_collisions": 148}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-097"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 2128, "makespan": 128, "avg_agents_density": 0.0955909335691295, "runtime": 31.624212242662907, "a_collisions": 244, "o_collisions": 112}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-098"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1854, "makespan": 128, "avg_agents_density": 0.07885933156987618, "runtime": 31.751350235193968, "a_collisions": 258, "o_collisions": 153}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-099"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1632, "makespan": 128, "avg_agents_density": 0.07385578149300288, "runtime": 30.874128077179193, "a_collisions": 172, "o_collisions": 223}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-100"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1608, "makespan": 128, "avg_agents_density": 0.06598140006452145, "runtime": 31.05062932893634, "a_collisions": 150, "o_collisions": 142}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-101"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 2042, "makespan": 128, "avg_agents_density": 0.09628729806788175, "runtime": 31.69649359025061, "a_collisions": 246, "o_collisions": 66}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-102"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 1428, "makespan": 128, "avg_agents_density": 0.06727249492767523, "runtime": 31.14678418263793, "a_collisions": 71, "o_collisions": 261}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-103"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1753, "makespan": 128, "avg_agents_density": 0.06809614363177553, "runtime": 32.15679166465998, "a_collisions": 160, "o_collisions": 183}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-104"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 2152, "makespan": 128, "avg_agents_density": 0.07580294262445317, "runtime": 32.145041186362505, "a_collisions": 194, "o_collisions": 131}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-105"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 1566, "makespan": 128, "avg_agents_density": 0.05361339149868831, "runtime": 31.92196409776807, "a_collisions": 85, "o_collisions": 333}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-106"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2042, "makespan": 128, "avg_agents_density": 0.07630485943099516, "runtime": 31.46458499506116, "a_collisions": 427, "o_collisions": 312}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-107"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1852, "makespan": 128, "avg_agents_density": 0.09168739686950507, "runtime": 30.8859360832721, "a_collisions": 292, "o_collisions": 143}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-108"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1942, "makespan": 128, "avg_agents_density": 0.07346321431850152, "runtime": 31.197096068412066, "a_collisions": 166, "o_collisions": 107}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-109"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 2123, "makespan": 128, "avg_agents_density": 0.08043927509724089, "runtime": 32.41302097402513, "a_collisions": 227, "o_collisions": 198}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-110"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1581, "makespan": 128, "avg_agents_density": 0.06953159240918315, "runtime": 31.132494198158383, "a_collisions": 44, "o_collisions": 341}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-111"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1943, "makespan": 128, "avg_agents_density": 0.09873980191577628, "runtime": 31.511657224968076, "a_collisions": 378, "o_collisions": 199}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-112"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1444, "makespan": 128, "avg_agents_density": 0.06335856005161866, "runtime": 32.44071728922427, "a_collisions": 57, "o_collisions": 228}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-113"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1681, "makespan": 128, "avg_agents_density": 0.06768792848390433, "runtime": 31.873306395485997, "a_collisions": 101, "o_collisions": 123}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-114"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1930, "makespan": 128, "avg_agents_density": 0.08088868990426816, "runtime": 31.032501615583897, "a_collisions": 147, "o_collisions": 191}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-115"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1933, "makespan": 128, "avg_agents_density": 0.08057679583086497, "runtime": 32.774503795430064, "a_collisions": 149, "o_collisions": 175}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-116"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.6666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1810, "makespan": 128, "avg_agents_density": 0.06881783099838974, "runtime": 31.350894359871745, "a_collisions": 59, "o_collisions": 338}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-117"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2083, "makespan": 128, "avg_agents_density": 0.0832950586731787, "runtime": 31.835150077939034, "a_collisions": 136, "o_collisions": 144}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-118"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1892, "makespan": 128, "avg_agents_density": 0.07646082361459967, "runtime": 31.63646168075502, "a_collisions": 189, "o_collisions": 178}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-119"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 1962, "makespan": 128, "avg_agents_density": 0.05154357332844533, "runtime": 31.784898715093732, "a_collisions": 84, "o_collisions": 381}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-120"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1906, "makespan": 128, "avg_agents_density": 0.07456801007310561, "runtime": 31.13723668642342, "a_collisions": 126, "o_collisions": 259}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-121"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1972, "makespan": 128, "avg_agents_density": 0.05855038781053601, "runtime": 34.04239062964916, "a_collisions": 206, "o_collisions": 120}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-122"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.7083333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1442, "makespan": 128, "avg_agents_density": 0.0630265802903239, "runtime": 32.39505650103092, "a_collisions": 59, "o_collisions": 374}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-123"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4583333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 2018, "makespan": 128, "avg_agents_density": 0.07308490372829916, "runtime": 31.006162140518427, "a_collisions": 260, "o_collisions": 136}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-124"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 2094, "makespan": 128, "avg_agents_density": 0.068149164201797, "runtime": 32.378495851531625, "a_collisions": 96, "o_collisions": 114}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-125"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4166666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 2312, "makespan": 128, "avg_agents_density": 0.10859108165350885, "runtime": 31.28685162216425, "a_collisions": 362, "o_collisions": 143}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-126"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 1623, "makespan": 128, "avg_agents_density": 0.06360617892712214, "runtime": 31.507392786443233, "a_collisions": 131, "o_collisions": 194}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-127"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 3088, "makespan": 128, "avg_agents_density": 0.09783416691653138, "runtime": 32.08503486402333, "a_collisions": 456, "o_collisions": 457}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3436, "makespan": 128, "avg_agents_density": 0.10997313450621397, "runtime": 31.559875156730413, "a_collisions": 427, "o_collisions": 608}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 127, "SoC": 2975, "makespan": 128, "avg_agents_density": 0.09061883753339858, "runtime": 32.37991274520755, "a_collisions": 440, "o_collisions": 662}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3062, "makespan": 128, "avg_agents_density": 0.08717987750767289, "runtime": 31.901705196127295, "a_collisions": 315, "o_collisions": 567}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 3145, "makespan": 128, "avg_agents_density": 0.0934541136725272, "runtime": 31.845530722290277, "a_collisions": 255, "o_collisions": 581}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3363, "makespan": 128, "avg_agents_density": 0.09357240078404892, "runtime": 32.39480905979872, "a_collisions": 484, "o_collisions": 436}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 2887, "makespan": 128, "avg_agents_density": 0.09911098022386233, "runtime": 32.268868586048484, "a_collisions": 254, "o_collisions": 799}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.28125, "CSR": 0.0, "ep_length": 127, "SoC": 3485, "makespan": 128, "avg_agents_density": 0.10178473103432076, "runtime": 30.177059845998883, "a_collisions": 570, "o_collisions": 686}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 3102, "makespan": 128, "avg_agents_density": 0.10905350329957789, "runtime": 33.02739851735532, "a_collisions": 399, "o_collisions": 630}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 3100, "makespan": 128, "avg_agents_density": 0.1062886414566321, "runtime": 32.65959057211876, "a_collisions": 154, "o_collisions": 496}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 127, "SoC": 3017, "makespan": 128, "avg_agents_density": 0.07878806587341812, "runtime": 33.534600691869855, "a_collisions": 288, "o_collisions": 584}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.34375, "CSR": 0.0, "ep_length": 127, "SoC": 3282, "makespan": 128, "avg_agents_density": 0.13588085945546735, "runtime": 32.18873248435557, "a_collisions": 758, "o_collisions": 518}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2859, "makespan": 128, "avg_agents_density": 0.10227678045216983, "runtime": 31.592012910172343, "a_collisions": 360, "o_collisions": 680}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 127, "SoC": 2655, "makespan": 128, "avg_agents_density": 0.09955228541363088, "runtime": 32.24289009720087, "a_collisions": 287, "o_collisions": 545}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 3204, "makespan": 128, "avg_agents_density": 0.1278600933114688, "runtime": 31.84743344038725, "a_collisions": 389, "o_collisions": 477}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 127, "SoC": 2758, "makespan": 128, "avg_agents_density": 0.08285876687992404, "runtime": 32.77754007279873, "a_collisions": 293, "o_collisions": 529}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 3272, "makespan": 128, "avg_agents_density": 0.11867546022296739, "runtime": 32.65873281471431, "a_collisions": 502, "o_collisions": 657}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 127, "SoC": 2921, "makespan": 128, "avg_agents_density": 0.07923975746254905, "runtime": 31.752498058602214, "a_collisions": 173, "o_collisions": 942}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.28125, "CSR": 0.0, "ep_length": 127, "SoC": 3541, "makespan": 128, "avg_agents_density": 0.12218048142162705, "runtime": 31.869464557617903, "a_collisions": 558, "o_collisions": 356}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.34375, "CSR": 0.0, "ep_length": 127, "SoC": 3310, "makespan": 128, "avg_agents_density": 0.11129288492652938, "runtime": 33.0862286798656, "a_collisions": 707, "o_collisions": 709}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 127, "SoC": 3255, "makespan": 128, "avg_agents_density": 0.08974879679571195, "runtime": 31.1957222931087, "a_collisions": 696, "o_collisions": 796}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3235, "makespan": 128, "avg_agents_density": 0.10876301333881971, "runtime": 32.88358413428068, "a_collisions": 773, "o_collisions": 710}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 3020, "makespan": 128, "avg_agents_density": 0.0803393988855294, "runtime": 31.45428543537855, "a_collisions": 270, "o_collisions": 851}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2890, "makespan": 128, "avg_agents_density": 0.11220860807850391, "runtime": 32.33780938945711, "a_collisions": 651, "o_collisions": 350}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 2896, "makespan": 128, "avg_agents_density": 0.10640386187336506, "runtime": 32.9575200099498, "a_collisions": 486, "o_collisions": 579}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 2660, "makespan": 128, "avg_agents_density": 0.08116570521238511, "runtime": 31.22353944554925, "a_collisions": 232, "o_collisions": 1077}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 127, "SoC": 2751, "makespan": 128, "avg_agents_density": 0.09231656932799577, "runtime": 31.768429540097713, "a_collisions": 300, "o_collisions": 878}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 2970, "makespan": 128, "avg_agents_density": 0.09587747481541607, "runtime": 31.407284712418914, "a_collisions": 324, "o_collisions": 771}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 3089, "makespan": 128, "avg_agents_density": 0.0855784681943786, "runtime": 32.07297796756029, "a_collisions": 312, "o_collisions": 644}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 3198, "makespan": 128, "avg_agents_density": 0.0937690445995977, "runtime": 32.390334729105234, "a_collisions": 487, "o_collisions": 632}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 2900, "makespan": 128, "avg_agents_density": 0.1089255605491137, "runtime": 31.351035738363862, "a_collisions": 545, "o_collisions": 534}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 127, "SoC": 2371, "makespan": 128, "avg_agents_density": 0.08232933081892092, "runtime": 31.1564534958452, "a_collisions": 134, "o_collisions": 1040}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 2996, "makespan": 128, "avg_agents_density": 0.11090248013840331, "runtime": 31.975010143592954, "a_collisions": 301, "o_collisions": 711}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-032"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.28125, "CSR": 0.0, "ep_length": 127, "SoC": 3548, "makespan": 128, "avg_agents_density": 0.1171103158825497, "runtime": 32.68995275720954, "a_collisions": 796, "o_collisions": 597}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-033"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 3040, "makespan": 128, "avg_agents_density": 0.14564347881501877, "runtime": 33.17903648503125, "a_collisions": 430, "o_collisions": 585}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-034"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.28125, "CSR": 0.0, "ep_length": 127, "SoC": 3222, "makespan": 128, "avg_agents_density": 0.11782809156510546, "runtime": 31.72497015632689, "a_collisions": 415, "o_collisions": 573}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-035"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 3035, "makespan": 128, "avg_agents_density": 0.131425111771996, "runtime": 32.297854566946626, "a_collisions": 502, "o_collisions": 243}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-036"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 3016, "makespan": 128, "avg_agents_density": 0.11652716637831102, "runtime": 32.14387272670865, "a_collisions": 567, "o_collisions": 469}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-037"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2644, "makespan": 128, "avg_agents_density": 0.09438905681512463, "runtime": 31.580853320658207, "a_collisions": 231, "o_collisions": 754}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-038"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.28125, "CSR": 0.0, "ep_length": 127, "SoC": 3517, "makespan": 128, "avg_agents_density": 0.10021403499095975, "runtime": 32.47961898520589, "a_collisions": 316, "o_collisions": 593}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-039"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3474, "makespan": 128, "avg_agents_density": 0.10249116772829785, "runtime": 32.51190936937928, "a_collisions": 464, "o_collisions": 748}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-040"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.34375, "CSR": 0.0, "ep_length": 127, "SoC": 3610, "makespan": 128, "avg_agents_density": 0.1065402013052202, "runtime": 31.053645869717002, "a_collisions": 596, "o_collisions": 692}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-041"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 2947, "makespan": 128, "avg_agents_density": 0.10532947451177203, "runtime": 31.382860308513045, "a_collisions": 380, "o_collisions": 665}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-042"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2679, "makespan": 128, "avg_agents_density": 0.07633340316612698, "runtime": 32.283172300085425, "a_collisions": 152, "o_collisions": 781}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-043"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 127, "SoC": 2651, "makespan": 128, "avg_agents_density": 0.09342444498866924, "runtime": 31.702492486685514, "a_collisions": 218, "o_collisions": 433}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-044"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 3402, "makespan": 128, "avg_agents_density": 0.11275299292659442, "runtime": 32.02970755286515, "a_collisions": 586, "o_collisions": 551}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-045"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2633, "makespan": 128, "avg_agents_density": 0.08153479873771875, "runtime": 31.310313964262605, "a_collisions": 183, "o_collisions": 644}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-046"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3046, "makespan": 128, "avg_agents_density": 0.10694264254123462, "runtime": 31.71690271049738, "a_collisions": 744, "o_collisions": 768}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-047"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 127, "SoC": 2639, "makespan": 128, "avg_agents_density": 0.10299397524363381, "runtime": 32.40641609765589, "a_collisions": 395, "o_collisions": 637}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-048"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 3185, "makespan": 128, "avg_agents_density": 0.11169086029691075, "runtime": 31.47533007711172, "a_collisions": 311, "o_collisions": 666}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-049"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 3474, "makespan": 128, "avg_agents_density": 0.12304807519887784, "runtime": 32.47374024800956, "a_collisions": 467, "o_collisions": 547}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-050"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3070, "makespan": 128, "avg_agents_density": 0.09151683208527248, "runtime": 32.573275273665786, "a_collisions": 384, "o_collisions": 819}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-051"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.28125, "CSR": 0.0, "ep_length": 127, "SoC": 3609, "makespan": 128, "avg_agents_density": 0.08322597043127368, "runtime": 32.97733432240784, "a_collisions": 463, "o_collisions": 351}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-052"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 3676, "makespan": 128, "avg_agents_density": 0.1599039063084035, "runtime": 31.656242622062564, "a_collisions": 1079, "o_collisions": 807}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-053"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 3254, "makespan": 128, "avg_agents_density": 0.11001330396485325, "runtime": 31.570551969110966, "a_collisions": 437, "o_collisions": 553}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-054"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3216, "makespan": 128, "avg_agents_density": 0.091873993125582, "runtime": 31.41633878275752, "a_collisions": 319, "o_collisions": 550}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-055"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2752, "makespan": 128, "avg_agents_density": 0.07836665229594898, "runtime": 32.08263085782528, "a_collisions": 376, "o_collisions": 852}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-056"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3017, "makespan": 128, "avg_agents_density": 0.10056756960574843, "runtime": 31.663266198709607, "a_collisions": 605, "o_collisions": 357}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-057"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3249, "makespan": 128, "avg_agents_density": 0.09143614826790325, "runtime": 31.461771972477436, "a_collisions": 552, "o_collisions": 700}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-058"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.28125, "CSR": 0.0, "ep_length": 127, "SoC": 3472, "makespan": 128, "avg_agents_density": 0.09907555167892201, "runtime": 32.12254763580859, "a_collisions": 447, "o_collisions": 597}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-059"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 2956, "makespan": 128, "avg_agents_density": 0.08132386126377905, "runtime": 31.909328756853938, "a_collisions": 148, "o_collisions": 430}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-060"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3109, "makespan": 128, "avg_agents_density": 0.11561419714482075, "runtime": 32.237626653164625, "a_collisions": 769, "o_collisions": 638}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-061"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3349, "makespan": 128, "avg_agents_density": 0.09908456951470423, "runtime": 32.289527425542474, "a_collisions": 287, "o_collisions": 735}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-062"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 3197, "makespan": 128, "avg_agents_density": 0.12984228027716796, "runtime": 31.789039969444275, "a_collisions": 1057, "o_collisions": 406}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-063"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 3178, "makespan": 128, "avg_agents_density": 0.12140792526416004, "runtime": 32.21499679982662, "a_collisions": 446, "o_collisions": 602}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-064"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.34375, "CSR": 0.0, "ep_length": 127, "SoC": 3585, "makespan": 128, "avg_agents_density": 0.12912566553281254, "runtime": 31.551360992714763, "a_collisions": 561, "o_collisions": 749}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-065"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 3111, "makespan": 128, "avg_agents_density": 0.10055666259667069, "runtime": 31.88997123390436, "a_collisions": 384, "o_collisions": 677}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-066"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 127, "SoC": 2546, "makespan": 128, "avg_agents_density": 0.08319810040058052, "runtime": 32.59948908537626, "a_collisions": 253, "o_collisions": 672}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-067"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.34375, "CSR": 0.0, "ep_length": 127, "SoC": 3427, "makespan": 128, "avg_agents_density": 0.11169564002465544, "runtime": 31.37249868363142, "a_collisions": 617, "o_collisions": 465}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-068"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.28125, "CSR": 0.0, "ep_length": 127, "SoC": 3528, "makespan": 128, "avg_agents_density": 0.10981863794847876, "runtime": 33.17837009206414, "a_collisions": 519, "o_collisions": 646}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-069"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 3491, "makespan": 128, "avg_agents_density": 0.10740180792413613, "runtime": 32.77100753970444, "a_collisions": 574, "o_collisions": 494}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-070"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.34375, "CSR": 0.0, "ep_length": 127, "SoC": 3285, "makespan": 128, "avg_agents_density": 0.10691234194218766, "runtime": 33.11830122768879, "a_collisions": 338, "o_collisions": 905}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-071"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2577, "makespan": 128, "avg_agents_density": 0.06804457547276777, "runtime": 32.00814522057772, "a_collisions": 272, "o_collisions": 861}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-072"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3119, "makespan": 128, "avg_agents_density": 0.11403940363820682, "runtime": 31.595860540866852, "a_collisions": 380, "o_collisions": 570}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-073"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 3566, "makespan": 128, "avg_agents_density": 0.1130303501091152, "runtime": 32.00506362505257, "a_collisions": 388, "o_collisions": 834}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-074"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2819, "makespan": 128, "avg_agents_density": 0.09818039431296756, "runtime": 33.41158097423613, "a_collisions": 185, "o_collisions": 965}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-075"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.34375, "CSR": 0.0, "ep_length": 127, "SoC": 3211, "makespan": 128, "avg_agents_density": 0.11246946589716378, "runtime": 33.15885263122618, "a_collisions": 477, "o_collisions": 596}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-076"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3245, "makespan": 128, "avg_agents_density": 0.09421515006333817, "runtime": 34.13996804319322, "a_collisions": 635, "o_collisions": 944}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-077"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 3200, "makespan": 128, "avg_agents_density": 0.10400251124778362, "runtime": 32.12965436838567, "a_collisions": 330, "o_collisions": 781}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-078"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2853, "makespan": 128, "avg_agents_density": 0.0863014956091559, "runtime": 32.54209558479488, "a_collisions": 298, "o_collisions": 707}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-079"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2503, "makespan": 128, "avg_agents_density": 0.08493438048619556, "runtime": 31.33067656494677, "a_collisions": 139, "o_collisions": 1164}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-080"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3118, "makespan": 128, "avg_agents_density": 0.11718554016625633, "runtime": 32.47697278484702, "a_collisions": 510, "o_collisions": 356}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-081"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 3208, "makespan": 128, "avg_agents_density": 0.10262204078731672, "runtime": 31.8531402181834, "a_collisions": 419, "o_collisions": 514}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-082"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 127, "SoC": 2657, "makespan": 128, "avg_agents_density": 0.0836206820711896, "runtime": 32.278920674696565, "a_collisions": 161, "o_collisions": 1045}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-083"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.28125, "CSR": 0.0, "ep_length": 127, "SoC": 3600, "makespan": 128, "avg_agents_density": 0.08390858289059165, "runtime": 32.950760589912534, "a_collisions": 648, "o_collisions": 616}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-084"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 3322, "makespan": 128, "avg_agents_density": 0.10391279146327977, "runtime": 31.944371961057186, "a_collisions": 436, "o_collisions": 738}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-085"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 2978, "makespan": 128, "avg_agents_density": 0.07842439493770449, "runtime": 31.973658569157124, "a_collisions": 129, "o_collisions": 829}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-086"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 3064, "makespan": 128, "avg_agents_density": 0.1166391260958657, "runtime": 31.831277009099722, "a_collisions": 638, "o_collisions": 394}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-087"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 3596, "makespan": 128, "avg_agents_density": 0.08562665210593715, "runtime": 31.939779728651047, "a_collisions": 451, "o_collisions": 838}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-088"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 2940, "makespan": 128, "avg_agents_density": 0.09792137666768094, "runtime": 32.47305332124233, "a_collisions": 267, "o_collisions": 575}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-089"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 3386, "makespan": 128, "avg_agents_density": 0.10008688889729908, "runtime": 32.34021755494177, "a_collisions": 690, "o_collisions": 590}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-090"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 127, "SoC": 3109, "makespan": 128, "avg_agents_density": 0.11373327711973821, "runtime": 32.1649391297251, "a_collisions": 342, "o_collisions": 463}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-091"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2751, "makespan": 128, "avg_agents_density": 0.0934678756597118, "runtime": 31.387398751452565, "a_collisions": 130, "o_collisions": 942}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-092"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3055, "makespan": 128, "avg_agents_density": 0.10246430571321985, "runtime": 32.34599824808538, "a_collisions": 314, "o_collisions": 591}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-093"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.28125, "CSR": 0.0, "ep_length": 127, "SoC": 3435, "makespan": 128, "avg_agents_density": 0.12650697321658744, "runtime": 32.98879506997764, "a_collisions": 674, "o_collisions": 677}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-094"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 3023, "makespan": 128, "avg_agents_density": 0.09544736339514451, "runtime": 32.64013735949993, "a_collisions": 528, "o_collisions": 560}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-095"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 3182, "makespan": 128, "avg_agents_density": 0.07894034489918761, "runtime": 32.87394438870251, "a_collisions": 390, "o_collisions": 758}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-096"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3099, "makespan": 128, "avg_agents_density": 0.09256148569745799, "runtime": 31.310787707567215, "a_collisions": 326, "o_collisions": 673}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-097"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 3368, "makespan": 128, "avg_agents_density": 0.11567734241116394, "runtime": 31.101066008210182, "a_collisions": 599, "o_collisions": 814}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-098"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.34375, "CSR": 0.0, "ep_length": 127, "SoC": 3268, "makespan": 128, "avg_agents_density": 0.10839405834689643, "runtime": 31.58924792893231, "a_collisions": 510, "o_collisions": 535}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-099"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 127, "SoC": 2664, "makespan": 128, "avg_agents_density": 0.0927416052841638, "runtime": 32.26800516247749, "a_collisions": 499, "o_collisions": 510}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-100"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 2971, "makespan": 128, "avg_agents_density": 0.0866215467562854, "runtime": 31.494515161961317, "a_collisions": 265, "o_collisions": 773}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-101"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3269, "makespan": 128, "avg_agents_density": 0.11006607926847982, "runtime": 32.0524760838598, "a_collisions": 390, "o_collisions": 557}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-102"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2621, "makespan": 128, "avg_agents_density": 0.08920374116620032, "runtime": 32.20301982574165, "a_collisions": 404, "o_collisions": 622}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-103"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 127, "SoC": 2951, "makespan": 128, "avg_agents_density": 0.08239838439169675, "runtime": 31.566036079078913, "a_collisions": 380, "o_collisions": 765}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-104"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 3436, "makespan": 128, "avg_agents_density": 0.11096668746923542, "runtime": 32.07138081267476, "a_collisions": 484, "o_collisions": 464}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-105"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2494, "makespan": 128, "avg_agents_density": 0.076372578213812, "runtime": 31.75042258016765, "a_collisions": 214, "o_collisions": 1013}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-106"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 3349, "makespan": 128, "avg_agents_density": 0.10989618554023242, "runtime": 31.552615839987993, "a_collisions": 643, "o_collisions": 784}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-107"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 3434, "makespan": 128, "avg_agents_density": 0.12769770997541313, "runtime": 32.27310212701559, "a_collisions": 717, "o_collisions": 400}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-108"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3346, "makespan": 128, "avg_agents_density": 0.11689898987722024, "runtime": 31.699088422581553, "a_collisions": 666, "o_collisions": 576}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-109"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 127, "SoC": 3177, "makespan": 128, "avg_agents_density": 0.10736842526230128, "runtime": 31.121694035828114, "a_collisions": 462, "o_collisions": 762}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-110"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2589, "makespan": 128, "avg_agents_density": 0.09156701280432818, "runtime": 31.72973987273872, "a_collisions": 159, "o_collisions": 906}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-111"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 3823, "makespan": 128, "avg_agents_density": 0.1241331999750846, "runtime": 32.72310329042375, "a_collisions": 506, "o_collisions": 511}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-112"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 2606, "makespan": 128, "avg_agents_density": 0.09062917451603561, "runtime": 33.057988019660115, "a_collisions": 392, "o_collisions": 784}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-113"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 127, "SoC": 2782, "makespan": 128, "avg_agents_density": 0.08905262448607174, "runtime": 31.75896167010069, "a_collisions": 284, "o_collisions": 806}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-114"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3062, "makespan": 128, "avg_agents_density": 0.09542700989603246, "runtime": 32.0648701004684, "a_collisions": 392, "o_collisions": 599}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-115"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 3284, "makespan": 128, "avg_agents_density": 0.12226624229590763, "runtime": 32.019797498360276, "a_collisions": 546, "o_collisions": 416}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-116"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 127, "SoC": 2540, "makespan": 128, "avg_agents_density": 0.08247740435345874, "runtime": 32.27656180039048, "a_collisions": 164, "o_collisions": 834}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-117"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 127, "SoC": 2946, "makespan": 128, "avg_agents_density": 0.10379196516425675, "runtime": 31.719797007739544, "a_collisions": 356, "o_collisions": 591}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-118"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 3311, "makespan": 128, "avg_agents_density": 0.10629699224486786, "runtime": 31.411927361041307, "a_collisions": 523, "o_collisions": 470}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-119"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 3039, "makespan": 128, "avg_agents_density": 0.06711962570176956, "runtime": 32.164983512833714, "a_collisions": 191, "o_collisions": 1038}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-120"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 127, "SoC": 2960, "makespan": 128, "avg_agents_density": 0.08624279264787903, "runtime": 32.295873304829, "a_collisions": 185, "o_collisions": 841}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-121"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 3017, "makespan": 128, "avg_agents_density": 0.08358655753344614, "runtime": 32.27130528353155, "a_collisions": 474, "o_collisions": 531}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-122"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.59375, "CSR": 0.0, "ep_length": 127, "SoC": 2292, "makespan": 128, "avg_agents_density": 0.09120603016313564, "runtime": 31.87345750257373, "a_collisions": 144, "o_collisions": 1156}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-123"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 3146, "makespan": 128, "avg_agents_density": 0.09895466053671598, "runtime": 31.784225571900606, "a_collisions": 604, "o_collisions": 562}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-124"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 3291, "makespan": 128, "avg_agents_density": 0.09975936336883008, "runtime": 32.54340512864292, "a_collisions": 394, "o_collisions": 483}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-125"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.28125, "CSR": 0.0, "ep_length": 127, "SoC": 3539, "makespan": 128, "avg_agents_density": 0.11844598316829395, "runtime": 32.016974141821265, "a_collisions": 782, "o_collisions": 809}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-126"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.46875, "CSR": 0.0, "ep_length": 127, "SoC": 2699, "makespan": 128, "avg_agents_density": 0.09619469137671918, "runtime": 31.569744950160384, "a_collisions": 279, "o_collisions": 826}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-127"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5033, "makespan": 128, "avg_agents_density": 0.13997645256240188, "runtime": 33.33152259327471, "a_collisions": 943, "o_collisions": 1295}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5649, "makespan": 128, "avg_agents_density": 0.17925990714710632, "runtime": 33.07028212212026, "a_collisions": 1623, "o_collisions": 1444}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5434, "makespan": 128, "avg_agents_density": 0.16287373418998757, "runtime": 32.99350658431649, "a_collisions": 1284, "o_collisions": 1422}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5202, "makespan": 128, "avg_agents_density": 0.15055031070464917, "runtime": 32.72927821800113, "a_collisions": 1298, "o_collisions": 1076}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 5049, "makespan": 128, "avg_agents_density": 0.1438871757782283, "runtime": 33.30434408597648, "a_collisions": 1221, "o_collisions": 1393}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5555, "makespan": 128, "avg_agents_density": 0.15316963464878236, "runtime": 33.50083921663463, "a_collisions": 1043, "o_collisions": 1286}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5173, "makespan": 128, "avg_agents_density": 0.15414053847697917, "runtime": 32.18993968330324, "a_collisions": 1167, "o_collisions": 1346}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.08333333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5813, "makespan": 128, "avg_agents_density": 0.1812356531985505, "runtime": 33.64247581735253, "a_collisions": 1405, "o_collisions": 1442}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.10416666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5926, "makespan": 128, "avg_agents_density": 0.16245385971090726, "runtime": 32.91827239654958, "a_collisions": 1487, "o_collisions": 1457}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5282, "makespan": 128, "avg_agents_density": 0.13972287048420673, "runtime": 33.07958338409662, "a_collisions": 879, "o_collisions": 1561}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3958333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 4848, "makespan": 128, "avg_agents_density": 0.11981093646161899, "runtime": 32.98288908228278, "a_collisions": 723, "o_collisions": 1669}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5645, "makespan": 128, "avg_agents_density": 0.18616467643699317, "runtime": 32.82316762395203, "a_collisions": 1670, "o_collisions": 1476}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 5654, "makespan": 128, "avg_agents_density": 0.17130071121303478, "runtime": 33.38052140548825, "a_collisions": 1226, "o_collisions": 1178}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3958333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 4752, "makespan": 128, "avg_agents_density": 0.14306034825774577, "runtime": 32.88934259302914, "a_collisions": 1089, "o_collisions": 1254}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5447, "makespan": 128, "avg_agents_density": 0.21259453437646414, "runtime": 33.48236547969282, "a_collisions": 1273, "o_collisions": 1395}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5477, "makespan": 128, "avg_agents_density": 0.13506005799603585, "runtime": 33.38230699673295, "a_collisions": 1086, "o_collisions": 1375}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5370, "makespan": 128, "avg_agents_density": 0.18339557878192675, "runtime": 32.853740429505706, "a_collisions": 1214, "o_collisions": 1752}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5150, "makespan": 128, "avg_agents_density": 0.1158583694707387, "runtime": 33.449602825567126, "a_collisions": 844, "o_collisions": 1922}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 5615, "makespan": 128, "avg_agents_density": 0.1905786038037352, "runtime": 33.13208665326238, "a_collisions": 1391, "o_collisions": 1273}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.10416666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5668, "makespan": 128, "avg_agents_density": 0.15379013095483068, "runtime": 33.11979940533638, "a_collisions": 1665, "o_collisions": 1767}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.10416666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5829, "makespan": 128, "avg_agents_density": 0.14500747104378242, "runtime": 33.241190791130066, "a_collisions": 1475, "o_collisions": 1563}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5456, "makespan": 128, "avg_agents_density": 0.18376984023210896, "runtime": 32.95548880659044, "a_collisions": 1302, "o_collisions": 1412}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5164, "makespan": 128, "avg_agents_density": 0.12606712726986716, "runtime": 33.42184731177986, "a_collisions": 1053, "o_collisions": 1317}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5195, "makespan": 128, "avg_agents_density": 0.1763045167625295, "runtime": 33.5057823471725, "a_collisions": 1065, "o_collisions": 1443}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5370, "makespan": 128, "avg_agents_density": 0.1655229102749847, "runtime": 32.922326263040304, "a_collisions": 1264, "o_collisions": 1373}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3333333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 4865, "makespan": 128, "avg_agents_density": 0.1564256231899636, "runtime": 32.510593520477414, "a_collisions": 1459, "o_collisions": 1323}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5138, "makespan": 128, "avg_agents_density": 0.16220457848699757, "runtime": 33.454382847994566, "a_collisions": 1344, "o_collisions": 1515}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 5321, "makespan": 128, "avg_agents_density": 0.1503313935789705, "runtime": 33.45851036719978, "a_collisions": 1209, "o_collisions": 1722}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 5614, "makespan": 128, "avg_agents_density": 0.1444333183240711, "runtime": 33.15055528841913, "a_collisions": 1117, "o_collisions": 1655}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3333333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5439, "makespan": 128, "avg_agents_density": 0.1950923439659544, "runtime": 32.11204970628023, "a_collisions": 1229, "o_collisions": 1355}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5036, "makespan": 128, "avg_agents_density": 0.17594856114931254, "runtime": 32.48352092690766, "a_collisions": 1129, "o_collisions": 1837}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3541666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4510, "makespan": 128, "avg_agents_density": 0.13978357019405072, "runtime": 32.57010564208031, "a_collisions": 857, "o_collisions": 1692}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5206, "makespan": 128, "avg_agents_density": 0.15141136649033005, "runtime": 33.056599436327815, "a_collisions": 1122, "o_collisions": 1385}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-032"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.14583333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5747, "makespan": 128, "avg_agents_density": 0.15640962082937188, "runtime": 34.09625867381692, "a_collisions": 1528, "o_collisions": 1297}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-033"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 5231, "makespan": 128, "avg_agents_density": 0.17866405349194395, "runtime": 32.94308150187135, "a_collisions": 1465, "o_collisions": 1340}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-034"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5287, "makespan": 128, "avg_agents_density": 0.1780871518471608, "runtime": 32.53061513788998, "a_collisions": 1364, "o_collisions": 1224}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-035"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5474, "makespan": 128, "avg_agents_density": 0.1974431265048267, "runtime": 32.26055968739092, "a_collisions": 1310, "o_collisions": 1116}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-036"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5549, "makespan": 128, "avg_agents_density": 0.15275012690016357, "runtime": 34.056255131959915, "a_collisions": 1322, "o_collisions": 1407}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-037"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 4854, "makespan": 128, "avg_agents_density": 0.15396526451582696, "runtime": 32.75817639939487, "a_collisions": 1538, "o_collisions": 1412}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-038"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5648, "makespan": 128, "avg_agents_density": 0.15880753966607014, "runtime": 33.37737126648426, "a_collisions": 925, "o_collisions": 1367}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-039"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 5754, "makespan": 128, "avg_agents_density": 0.16217105438614018, "runtime": 34.05054880864918, "a_collisions": 1482, "o_collisions": 1637}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-040"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5673, "makespan": 128, "avg_agents_density": 0.13982474657759716, "runtime": 33.216395827010274, "a_collisions": 1101, "o_collisions": 1649}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-041"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5366, "makespan": 128, "avg_agents_density": 0.18364986109559978, "runtime": 33.83895066007972, "a_collisions": 1350, "o_collisions": 1439}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-042"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3541666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4798, "makespan": 128, "avg_agents_density": 0.13503254138898438, "runtime": 32.80196753330529, "a_collisions": 838, "o_collisions": 1623}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-043"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 5096, "makespan": 128, "avg_agents_density": 0.17113034899202112, "runtime": 33.252121387049556, "a_collisions": 1131, "o_collisions": 1188}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-044"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5445, "makespan": 128, "avg_agents_density": 0.16846799668246373, "runtime": 32.99343255534768, "a_collisions": 1276, "o_collisions": 1413}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-045"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.375, "CSR": 0.0, "ep_length": 127, "SoC": 4747, "makespan": 128, "avg_agents_density": 0.1291633716380725, "runtime": 33.144076615571976, "a_collisions": 859, "o_collisions": 1479}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-046"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 5587, "makespan": 128, "avg_agents_density": 0.1795288410350213, "runtime": 33.588521130383015, "a_collisions": 1538, "o_collisions": 1420}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-047"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5134, "makespan": 128, "avg_agents_density": 0.1651214591796032, "runtime": 32.45257273502648, "a_collisions": 1116, "o_collisions": 1353}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-048"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 5458, "makespan": 128, "avg_agents_density": 0.17875843369437364, "runtime": 33.8586978148669, "a_collisions": 1350, "o_collisions": 1363}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-049"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5508, "makespan": 128, "avg_agents_density": 0.15286688687351593, "runtime": 34.09830954670906, "a_collisions": 1106, "o_collisions": 1335}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-050"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5571, "makespan": 128, "avg_agents_density": 0.13077581148422676, "runtime": 32.51942370086908, "a_collisions": 699, "o_collisions": 1715}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-051"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5544, "makespan": 128, "avg_agents_density": 0.14063473815817076, "runtime": 33.463572178035975, "a_collisions": 1227, "o_collisions": 1209}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-052"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.0625, "CSR": 0.0, "ep_length": 127, "SoC": 5965, "makespan": 128, "avg_agents_density": 0.20528439878784857, "runtime": 33.73228877782822, "a_collisions": 1631, "o_collisions": 1404}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-053"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5191, "makespan": 128, "avg_agents_density": 0.1561245431222535, "runtime": 33.15261075086892, "a_collisions": 1063, "o_collisions": 1539}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-054"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 5038, "makespan": 128, "avg_agents_density": 0.14217852490326474, "runtime": 33.45615565031767, "a_collisions": 1060, "o_collisions": 1384}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-055"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4861, "makespan": 128, "avg_agents_density": 0.1610826880248242, "runtime": 33.90439476445317, "a_collisions": 857, "o_collisions": 1673}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-056"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5231, "makespan": 128, "avg_agents_density": 0.16505014197745102, "runtime": 33.41551936045289, "a_collisions": 1379, "o_collisions": 1392}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-057"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5567, "makespan": 128, "avg_agents_density": 0.15705976939205685, "runtime": 32.86530094221234, "a_collisions": 1622, "o_collisions": 1187}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-058"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5622, "makespan": 128, "avg_agents_density": 0.14604050435696947, "runtime": 34.00661741942167, "a_collisions": 1197, "o_collisions": 1302}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-059"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 5086, "makespan": 128, "avg_agents_density": 0.15274159834445578, "runtime": 33.274448890239, "a_collisions": 843, "o_collisions": 1279}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-060"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 5301, "makespan": 128, "avg_agents_density": 0.1879785010019387, "runtime": 32.38998510874808, "a_collisions": 1435, "o_collisions": 1663}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-061"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5674, "makespan": 128, "avg_agents_density": 0.18471463781443215, "runtime": 33.34631463140249, "a_collisions": 1241, "o_collisions": 1573}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-062"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5623, "makespan": 128, "avg_agents_density": 0.18394020607110523, "runtime": 33.07268555276096, "a_collisions": 1622, "o_collisions": 1509}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-063"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 5670, "makespan": 128, "avg_agents_density": 0.1828012433470819, "runtime": 33.94995318725705, "a_collisions": 1427, "o_collisions": 1535}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-064"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.14583333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5723, "makespan": 128, "avg_agents_density": 0.19298961123642816, "runtime": 33.29586552083492, "a_collisions": 1480, "o_collisions": 1568}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-065"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 5658, "makespan": 128, "avg_agents_density": 0.141896924439584, "runtime": 32.95215895585716, "a_collisions": 1296, "o_collisions": 1816}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-066"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4647, "makespan": 128, "avg_agents_density": 0.1350542076134574, "runtime": 32.985453967005014, "a_collisions": 910, "o_collisions": 1612}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-067"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.10416666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5810, "makespan": 128, "avg_agents_density": 0.15934889862224663, "runtime": 32.15739421546459, "a_collisions": 1174, "o_collisions": 1745}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-068"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5508, "makespan": 128, "avg_agents_density": 0.20707007745317857, "runtime": 33.27193613909185, "a_collisions": 1471, "o_collisions": 1434}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-069"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5653, "makespan": 128, "avg_agents_density": 0.17236238279950544, "runtime": 33.20532443001866, "a_collisions": 1377, "o_collisions": 1372}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-070"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5577, "makespan": 128, "avg_agents_density": 0.16040140964353058, "runtime": 32.873433135449886, "a_collisions": 1428, "o_collisions": 1479}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-071"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4827, "makespan": 128, "avg_agents_density": 0.12745982871312078, "runtime": 32.95038867741823, "a_collisions": 1131, "o_collisions": 1652}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-072"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5082, "makespan": 128, "avg_agents_density": 0.14068270246431658, "runtime": 32.82023133337498, "a_collisions": 939, "o_collisions": 1334}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-073"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5441, "makespan": 128, "avg_agents_density": 0.2011574965346856, "runtime": 33.51532481238246, "a_collisions": 1162, "o_collisions": 1641}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-074"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 5029, "makespan": 128, "avg_agents_density": 0.16311938145099172, "runtime": 33.18518923223019, "a_collisions": 1184, "o_collisions": 1665}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-075"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5844, "makespan": 128, "avg_agents_density": 0.19585366449792949, "runtime": 33.42563348263502, "a_collisions": 1528, "o_collisions": 1263}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-076"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5888, "makespan": 128, "avg_agents_density": 0.1954490952396059, "runtime": 34.179029047489166, "a_collisions": 1389, "o_collisions": 1768}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-077"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5510, "makespan": 128, "avg_agents_density": 0.15540285447865085, "runtime": 32.625895446166396, "a_collisions": 1372, "o_collisions": 1304}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-078"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5100, "makespan": 128, "avg_agents_density": 0.15948348804004817, "runtime": 33.071762550622225, "a_collisions": 1284, "o_collisions": 1179}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-079"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4797, "makespan": 128, "avg_agents_density": 0.13810756770275312, "runtime": 32.69332060776651, "a_collisions": 1050, "o_collisions": 1613}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-080"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3541666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4919, "makespan": 128, "avg_agents_density": 0.17582598808967495, "runtime": 33.44853280298412, "a_collisions": 1498, "o_collisions": 1120}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-081"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5668, "makespan": 128, "avg_agents_density": 0.1574841748764105, "runtime": 32.93520478904247, "a_collisions": 1468, "o_collisions": 1332}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-082"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4876, "makespan": 128, "avg_agents_density": 0.14850336597218938, "runtime": 33.672089194878936, "a_collisions": 942, "o_collisions": 1656}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-083"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 5901, "makespan": 128, "avg_agents_density": 0.14647124296519456, "runtime": 32.95768054947257, "a_collisions": 1172, "o_collisions": 1417}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-084"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 5564, "makespan": 128, "avg_agents_density": 0.16781754446823272, "runtime": 33.09782827831805, "a_collisions": 1367, "o_collisions": 1397}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-085"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5307, "makespan": 128, "avg_agents_density": 0.1442608155485844, "runtime": 33.87812218442559, "a_collisions": 1043, "o_collisions": 1571}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-086"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5402, "makespan": 128, "avg_agents_density": 0.1749744743722744, "runtime": 33.523816242814064, "a_collisions": 1449, "o_collisions": 1499}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-087"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5589, "makespan": 128, "avg_agents_density": 0.14401668292547237, "runtime": 33.756133733317256, "a_collisions": 1526, "o_collisions": 1689}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-088"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 5440, "makespan": 128, "avg_agents_density": 0.1457112509359333, "runtime": 32.4971535038203, "a_collisions": 1159, "o_collisions": 1209}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-089"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 5299, "makespan": 128, "avg_agents_density": 0.1817642782190147, "runtime": 34.150875601917505, "a_collisions": 1270, "o_collisions": 1403}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-090"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5342, "makespan": 128, "avg_agents_density": 0.16702189491399325, "runtime": 34.30468637123704, "a_collisions": 1811, "o_collisions": 1121}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-091"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4912, "makespan": 128, "avg_agents_density": 0.1531352560837891, "runtime": 34.17312107048929, "a_collisions": 856, "o_collisions": 1679}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-092"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5494, "makespan": 128, "avg_agents_density": 0.13004006136365068, "runtime": 33.174503019079566, "a_collisions": 791, "o_collisions": 1505}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-093"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5804, "makespan": 128, "avg_agents_density": 0.20782919644360218, "runtime": 33.50557444430888, "a_collisions": 1625, "o_collisions": 1684}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-094"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 5533, "makespan": 128, "avg_agents_density": 0.16404234940390264, "runtime": 33.289062859490514, "a_collisions": 1392, "o_collisions": 1462}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-095"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 5640, "makespan": 128, "avg_agents_density": 0.14676907473903947, "runtime": 32.34777308627963, "a_collisions": 1389, "o_collisions": 1635}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-096"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 5344, "makespan": 128, "avg_agents_density": 0.19047741143398234, "runtime": 33.506214682012796, "a_collisions": 1160, "o_collisions": 1479}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-097"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5500, "makespan": 128, "avg_agents_density": 0.17648740278371292, "runtime": 33.1555425170809, "a_collisions": 1510, "o_collisions": 1669}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-098"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 5534, "makespan": 128, "avg_agents_density": 0.19018964006748515, "runtime": 32.930322371423244, "a_collisions": 1503, "o_collisions": 1245}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-099"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 5032, "makespan": 128, "avg_agents_density": 0.13850542923407255, "runtime": 33.23971190303564, "a_collisions": 854, "o_collisions": 1443}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-100"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 5473, "makespan": 128, "avg_agents_density": 0.13927983984502199, "runtime": 33.62204931117594, "a_collisions": 1002, "o_collisions": 1644}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-101"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5579, "makespan": 128, "avg_agents_density": 0.16988464615683713, "runtime": 32.8572664540261, "a_collisions": 1324, "o_collisions": 1475}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-102"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4905, "makespan": 128, "avg_agents_density": 0.15439529662672438, "runtime": 32.87740203551948, "a_collisions": 1454, "o_collisions": 1093}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-103"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3125, "CSR": 0.0, "ep_length": 127, "SoC": 5293, "makespan": 128, "avg_agents_density": 0.14119638054673195, "runtime": 33.23968939483166, "a_collisions": 757, "o_collisions": 1564}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-104"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5553, "makespan": 128, "avg_agents_density": 0.16689841465147318, "runtime": 33.959794379770756, "a_collisions": 1402, "o_collisions": 1448}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-105"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4929, "makespan": 128, "avg_agents_density": 0.13317484612363126, "runtime": 32.73750377818942, "a_collisions": 921, "o_collisions": 1603}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-106"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5625, "makespan": 128, "avg_agents_density": 0.18507243246821148, "runtime": 34.792610900476575, "a_collisions": 1658, "o_collisions": 1547}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-107"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5532, "makespan": 128, "avg_agents_density": 0.1879805957604993, "runtime": 34.213092064484954, "a_collisions": 1644, "o_collisions": 1252}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-108"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5396, "makespan": 128, "avg_agents_density": 0.17037683423201697, "runtime": 34.449329141527414, "a_collisions": 1385, "o_collisions": 1400}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-109"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5481, "makespan": 128, "avg_agents_density": 0.18048817551383442, "runtime": 33.01631273701787, "a_collisions": 1602, "o_collisions": 1346}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-110"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4654, "makespan": 128, "avg_agents_density": 0.14747809365409079, "runtime": 33.40984336659312, "a_collisions": 1393, "o_collisions": 1316}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-111"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 5512, "makespan": 128, "avg_agents_density": 0.18809018289776225, "runtime": 32.7094466984272, "a_collisions": 1778, "o_collisions": 1493}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-112"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3541666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4655, "makespan": 128, "avg_agents_density": 0.15591761519124253, "runtime": 33.16403788886964, "a_collisions": 1461, "o_collisions": 1172}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-113"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3333333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 4949, "makespan": 128, "avg_agents_density": 0.15850770559581948, "runtime": 32.62454757280648, "a_collisions": 1361, "o_collisions": 1413}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-114"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.14583333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5534, "makespan": 128, "avg_agents_density": 0.13471497683760023, "runtime": 33.063569063320756, "a_collisions": 1453, "o_collisions": 1080}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-115"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 5554, "makespan": 128, "avg_agents_density": 0.18266389923144563, "runtime": 33.61792485229671, "a_collisions": 1150, "o_collisions": 1553}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-116"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3333333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 4784, "makespan": 128, "avg_agents_density": 0.1507516573149895, "runtime": 32.94569964334369, "a_collisions": 980, "o_collisions": 1347}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-117"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5216, "makespan": 128, "avg_agents_density": 0.1685817958025863, "runtime": 33.66325803846121, "a_collisions": 1560, "o_collisions": 1252}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-118"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 5395, "makespan": 128, "avg_agents_density": 0.1680647421848501, "runtime": 32.76763204112649, "a_collisions": 1246, "o_collisions": 1616}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-119"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2916666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4970, "makespan": 128, "avg_agents_density": 0.12414437063499607, "runtime": 33.02935783006251, "a_collisions": 1016, "o_collisions": 1839}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-120"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.20833333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 5501, "makespan": 128, "avg_agents_density": 0.14536821237698888, "runtime": 32.28175398893654, "a_collisions": 808, "o_collisions": 1620}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-121"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 5286, "makespan": 128, "avg_agents_density": 0.14731312495062981, "runtime": 33.192159455269575, "a_collisions": 1045, "o_collisions": 1455}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-122"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.2708333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 4783, "makespan": 128, "avg_agents_density": 0.162635658864773, "runtime": 33.83225330710411, "a_collisions": 878, "o_collisions": 1726}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-123"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.16666666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5692, "makespan": 128, "avg_agents_density": 0.14281994488544378, "runtime": 32.39126410521567, "a_collisions": 1695, "o_collisions": 1252}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-124"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.22916666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5484, "makespan": 128, "avg_agents_density": 0.15113766786615979, "runtime": 33.882202196866274, "a_collisions": 1003, "o_collisions": 1561}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-125"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 5730, "makespan": 128, "avg_agents_density": 0.19902173955862854, "runtime": 33.423483761027455, "a_collisions": 1943, "o_collisions": 1551}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-126"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.3333333333333333, "CSR": 0.0, "ep_length": 127, "SoC": 4867, "makespan": 128, "avg_agents_density": 0.16644766860355067, "runtime": 33.46069848164916, "a_collisions": 1395, "o_collisions": 1269}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-127"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.171875, "CSR": 0.0, "ep_length": 127, "SoC": 7429, "makespan": 128, "avg_agents_density": 0.22648709108043194, "runtime": 35.24828830361366, "a_collisions": 2211, "o_collisions": 2122}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.078125, "CSR": 0.0, "ep_length": 127, "SoC": 7997, "makespan": 128, "avg_agents_density": 0.2622934334742868, "runtime": 34.7991343177855, "a_collisions": 2398, "o_collisions": 2344}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 7549, "makespan": 128, "avg_agents_density": 0.2559586679098311, "runtime": 36.01670085825026, "a_collisions": 2405, "o_collisions": 2242}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 7095, "makespan": 128, "avg_agents_density": 0.22834097227423206, "runtime": 34.5849979147315, "a_collisions": 2630, "o_collisions": 2113}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.203125, "CSR": 0.0, "ep_length": 127, "SoC": 7536, "makespan": 128, "avg_agents_density": 0.21480042069110258, "runtime": 34.40338018722832, "a_collisions": 2195, "o_collisions": 1788}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7656, "makespan": 128, "avg_agents_density": 0.21790818878206528, "runtime": 34.890663450583816, "a_collisions": 2386, "o_collisions": 2302}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7740, "makespan": 128, "avg_agents_density": 0.1962221607902536, "runtime": 34.96506338566542, "a_collisions": 2336, "o_collisions": 2224}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.046875, "CSR": 0.0, "ep_length": 127, "SoC": 8049, "makespan": 128, "avg_agents_density": 0.24159940815650607, "runtime": 34.51412706077099, "a_collisions": 2963, "o_collisions": 2542}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7931, "makespan": 128, "avg_agents_density": 0.25468116690429327, "runtime": 36.884867161512375, "a_collisions": 2478, "o_collisions": 2204}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.203125, "CSR": 0.0, "ep_length": 127, "SoC": 7559, "makespan": 128, "avg_agents_density": 0.20883817425820617, "runtime": 35.308103650808334, "a_collisions": 1729, "o_collisions": 2366}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.203125, "CSR": 0.0, "ep_length": 127, "SoC": 7556, "makespan": 128, "avg_agents_density": 0.16900220241145356, "runtime": 35.035136479884386, "a_collisions": 1662, "o_collisions": 2551}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.09375, "CSR": 0.0, "ep_length": 127, "SoC": 7778, "makespan": 128, "avg_agents_density": 0.27676947416544057, "runtime": 37.03731111995876, "a_collisions": 3091, "o_collisions": 2127}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 7186, "makespan": 128, "avg_agents_density": 0.25463775564623853, "runtime": 35.69160762988031, "a_collisions": 2535, "o_collisions": 2077}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 7377, "makespan": 128, "avg_agents_density": 0.22343512815677263, "runtime": 36.15785081870854, "a_collisions": 2490, "o_collisions": 1854}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.09375, "CSR": 0.0, "ep_length": 127, "SoC": 7693, "makespan": 128, "avg_agents_density": 0.3112043724670393, "runtime": 37.07945107668638, "a_collisions": 2695, "o_collisions": 2023}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.171875, "CSR": 0.0, "ep_length": 127, "SoC": 7292, "makespan": 128, "avg_agents_density": 0.21635783929991653, "runtime": 35.305072877556086, "a_collisions": 2104, "o_collisions": 2238}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7527, "makespan": 128, "avg_agents_density": 0.24080267252035045, "runtime": 35.17511932551861, "a_collisions": 2680, "o_collisions": 2030}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.171875, "CSR": 0.0, "ep_length": 127, "SoC": 7597, "makespan": 128, "avg_agents_density": 0.18403605074762414, "runtime": 35.97839951515198, "a_collisions": 1810, "o_collisions": 2478}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7619, "makespan": 128, "avg_agents_density": 0.20912835297674365, "runtime": 34.58114487864077, "a_collisions": 2204, "o_collisions": 2262}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.0625, "CSR": 0.0, "ep_length": 127, "SoC": 7918, "makespan": 128, "avg_agents_density": 0.23084798977128118, "runtime": 34.20306660421193, "a_collisions": 2592, "o_collisions": 2567}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.09375, "CSR": 0.0, "ep_length": 127, "SoC": 7873, "makespan": 128, "avg_agents_density": 0.21363645945949378, "runtime": 35.61736090481281, "a_collisions": 2673, "o_collisions": 2609}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7617, "makespan": 128, "avg_agents_density": 0.25009637099374715, "runtime": 34.69734402000904, "a_collisions": 2613, "o_collisions": 2321}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 7236, "makespan": 128, "avg_agents_density": 0.17614669737741306, "runtime": 33.88791180588305, "a_collisions": 1825, "o_collisions": 2527}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7439, "makespan": 128, "avg_agents_density": 0.21629965355050557, "runtime": 35.94298274256289, "a_collisions": 2371, "o_collisions": 2247}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.171875, "CSR": 0.0, "ep_length": 127, "SoC": 7444, "makespan": 128, "avg_agents_density": 0.21124164513626728, "runtime": 33.65692653506994, "a_collisions": 2500, "o_collisions": 2256}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 6992, "makespan": 128, "avg_agents_density": 0.24045679905245496, "runtime": 35.571483083069324, "a_collisions": 2944, "o_collisions": 1858}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 7132, "makespan": 128, "avg_agents_density": 0.26408793384842877, "runtime": 36.046577762812376, "a_collisions": 2717, "o_collisions": 2182}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.171875, "CSR": 0.0, "ep_length": 127, "SoC": 7319, "makespan": 128, "avg_agents_density": 0.20447621447198075, "runtime": 34.826435044407845, "a_collisions": 2413, "o_collisions": 2142}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 7627, "makespan": 128, "avg_agents_density": 0.21534274280233662, "runtime": 36.167054975405335, "a_collisions": 2535, "o_collisions": 2373}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7687, "makespan": 128, "avg_agents_density": 0.2732376467598795, "runtime": 36.13651592284441, "a_collisions": 3301, "o_collisions": 2103}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.15625, "CSR": 0.0, "ep_length": 127, "SoC": 7480, "makespan": 128, "avg_agents_density": 0.26326204639285167, "runtime": 34.56261215545237, "a_collisions": 2410, "o_collisions": 2327}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 6974, "makespan": 128, "avg_agents_density": 0.20180469063740314, "runtime": 40.234874460846186, "a_collisions": 2041, "o_collisions": 2314}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.15625, "CSR": 0.0, "ep_length": 127, "SoC": 7458, "makespan": 128, "avg_agents_density": 0.27116649331026155, "runtime": 34.72637020982802, "a_collisions": 2750, "o_collisions": 2242}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-032"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 7722, "makespan": 128, "avg_agents_density": 0.2146359010512012, "runtime": 35.01439263485372, "a_collisions": 2599, "o_collisions": 2391}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-033"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7819, "makespan": 128, "avg_agents_density": 0.25161325659316663, "runtime": 35.4594951774925, "a_collisions": 3069, "o_collisions": 2205}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-034"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7832, "makespan": 128, "avg_agents_density": 0.27415430518217976, "runtime": 35.06911967508495, "a_collisions": 2255, "o_collisions": 1876}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-035"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7505, "makespan": 128, "avg_agents_density": 0.34900774929564243, "runtime": 33.95816143602133, "a_collisions": 2691, "o_collisions": 2057}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-036"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.15625, "CSR": 0.0, "ep_length": 127, "SoC": 7623, "makespan": 128, "avg_agents_density": 0.20392532338436523, "runtime": 35.35323371179402, "a_collisions": 2239, "o_collisions": 2420}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-037"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.203125, "CSR": 0.0, "ep_length": 127, "SoC": 7103, "makespan": 128, "avg_agents_density": 0.22879472026528222, "runtime": 34.532312674447894, "a_collisions": 2881, "o_collisions": 1828}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-038"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.0625, "CSR": 0.0, "ep_length": 127, "SoC": 7955, "makespan": 128, "avg_agents_density": 0.21335954043903985, "runtime": 35.244252014905214, "a_collisions": 2614, "o_collisions": 2087}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-039"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.0625, "CSR": 0.0, "ep_length": 127, "SoC": 8011, "makespan": 128, "avg_agents_density": 0.2079289503700574, "runtime": 37.084148025140166, "a_collisions": 2326, "o_collisions": 2459}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-040"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7922, "makespan": 128, "avg_agents_density": 0.21053616514664997, "runtime": 36.34387659840286, "a_collisions": 2287, "o_collisions": 2457}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-041"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.15625, "CSR": 0.0, "ep_length": 127, "SoC": 7591, "makespan": 128, "avg_agents_density": 0.26268819404687865, "runtime": 34.76658050343394, "a_collisions": 2486, "o_collisions": 2122}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-042"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.25, "CSR": 0.0, "ep_length": 127, "SoC": 7060, "makespan": 128, "avg_agents_density": 0.18856625957160816, "runtime": 35.33018958941102, "a_collisions": 2352, "o_collisions": 2138}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-043"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 7165, "makespan": 128, "avg_agents_density": 0.23054275227205015, "runtime": 35.43092433921993, "a_collisions": 2287, "o_collisions": 1866}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-044"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.171875, "CSR": 0.0, "ep_length": 127, "SoC": 7554, "makespan": 128, "avg_agents_density": 0.20297301205482832, "runtime": 35.20850733295083, "a_collisions": 1714, "o_collisions": 2980}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-045"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 7150, "makespan": 128, "avg_agents_density": 0.17777597383491012, "runtime": 34.701739992946386, "a_collisions": 2198, "o_collisions": 2255}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-046"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.15625, "CSR": 0.0, "ep_length": 127, "SoC": 7336, "makespan": 128, "avg_agents_density": 0.2374726515161608, "runtime": 33.941365119069815, "a_collisions": 2435, "o_collisions": 2221}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-047"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7625, "makespan": 128, "avg_agents_density": 0.24170242033960357, "runtime": 34.56272609345615, "a_collisions": 2787, "o_collisions": 2089}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-048"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 7524, "makespan": 128, "avg_agents_density": 0.28221050199505393, "runtime": 34.2092612311244, "a_collisions": 2933, "o_collisions": 2107}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-049"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7860, "makespan": 128, "avg_agents_density": 0.21905150102170448, "runtime": 35.08685702458024, "a_collisions": 2523, "o_collisions": 1966}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-050"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 7713, "makespan": 128, "avg_agents_density": 0.21480163309003386, "runtime": 33.5215904340148, "a_collisions": 2435, "o_collisions": 2033}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-051"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.09375, "CSR": 0.0, "ep_length": 127, "SoC": 7917, "makespan": 128, "avg_agents_density": 0.19355594386402825, "runtime": 35.04987216182053, "a_collisions": 2225, "o_collisions": 2097}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-052"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.015625, "CSR": 0.0, "ep_length": 127, "SoC": 8066, "makespan": 128, "avg_agents_density": 0.26085503336334137, "runtime": 35.07149349153042, "a_collisions": 3015, "o_collisions": 2375}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-053"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.09375, "CSR": 0.0, "ep_length": 127, "SoC": 7663, "makespan": 128, "avg_agents_density": 0.21813188114693727, "runtime": 36.46141635812819, "a_collisions": 2065, "o_collisions": 2561}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-054"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.171875, "CSR": 0.0, "ep_length": 127, "SoC": 7455, "makespan": 128, "avg_agents_density": 0.22232772786541766, "runtime": 38.43799953348935, "a_collisions": 1998, "o_collisions": 2286}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-055"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.234375, "CSR": 0.0, "ep_length": 127, "SoC": 7058, "makespan": 128, "avg_agents_density": 0.21849706925226084, "runtime": 37.970318999141455, "a_collisions": 2204, "o_collisions": 2256}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-056"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 7563, "makespan": 128, "avg_agents_density": 0.22632492802079107, "runtime": 36.55074837990105, "a_collisions": 2823, "o_collisions": 2218}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-057"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 7885, "makespan": 128, "avg_agents_density": 0.263771746550832, "runtime": 36.96783419884741, "a_collisions": 2816, "o_collisions": 2484}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-058"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 7765, "makespan": 128, "avg_agents_density": 0.2532606672971525, "runtime": 39.119507959112525, "a_collisions": 2279, "o_collisions": 2364}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-059"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.203125, "CSR": 0.0, "ep_length": 127, "SoC": 7089, "makespan": 128, "avg_agents_density": 0.23276053091402474, "runtime": 35.93112699314952, "a_collisions": 2631, "o_collisions": 1912}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-060"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.15625, "CSR": 0.0, "ep_length": 127, "SoC": 7505, "makespan": 128, "avg_agents_density": 0.23508645452793958, "runtime": 36.31445303745568, "a_collisions": 2212, "o_collisions": 2634}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-061"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.171875, "CSR": 0.0, "ep_length": 127, "SoC": 7666, "makespan": 128, "avg_agents_density": 0.23607179773933498, "runtime": 40.17766501568258, "a_collisions": 1823, "o_collisions": 2547}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-062"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.09375, "CSR": 0.0, "ep_length": 127, "SoC": 7761, "makespan": 128, "avg_agents_density": 0.24184361614159192, "runtime": 35.8629662450403, "a_collisions": 3138, "o_collisions": 2047}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-063"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 7759, "makespan": 128, "avg_agents_density": 0.24841703000072593, "runtime": 34.7938234526664, "a_collisions": 2453, "o_collisions": 2387}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-064"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7929, "makespan": 128, "avg_agents_density": 0.279671750878278, "runtime": 35.371508814394474, "a_collisions": 2680, "o_collisions": 2340}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-065"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7787, "makespan": 128, "avg_agents_density": 0.20399444130293226, "runtime": 35.11430365033448, "a_collisions": 2268, "o_collisions": 2151}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-066"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 6816, "makespan": 128, "avg_agents_density": 0.20858192554090757, "runtime": 33.89238472096622, "a_collisions": 2575, "o_collisions": 2018}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-067"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7737, "makespan": 128, "avg_agents_density": 0.21819410055453384, "runtime": 34.82504471205175, "a_collisions": 2369, "o_collisions": 2580}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-068"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7642, "makespan": 128, "avg_agents_density": 0.27085172070581426, "runtime": 34.7493844255805, "a_collisions": 3419, "o_collisions": 2091}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-069"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.15625, "CSR": 0.0, "ep_length": 127, "SoC": 7701, "makespan": 128, "avg_agents_density": 0.20525474377148922, "runtime": 34.497114047408104, "a_collisions": 2466, "o_collisions": 2120}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-070"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7793, "makespan": 128, "avg_agents_density": 0.23342190216147807, "runtime": 35.090195847675204, "a_collisions": 2641, "o_collisions": 2136}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-071"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 6675, "makespan": 128, "avg_agents_density": 0.22846499017837196, "runtime": 34.50890538096428, "a_collisions": 3340, "o_collisions": 1774}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-072"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.171875, "CSR": 0.0, "ep_length": 127, "SoC": 7459, "makespan": 128, "avg_agents_density": 0.2392788036842076, "runtime": 35.14129348658025, "a_collisions": 2263, "o_collisions": 2075}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-073"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7734, "makespan": 128, "avg_agents_density": 0.22518858190023608, "runtime": 35.0439653750509, "a_collisions": 2225, "o_collisions": 2428}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-074"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 7695, "makespan": 128, "avg_agents_density": 0.2196850279753009, "runtime": 34.501557191833854, "a_collisions": 2814, "o_collisions": 2111}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-075"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.15625, "CSR": 0.0, "ep_length": 127, "SoC": 7713, "makespan": 128, "avg_agents_density": 0.25228150009556016, "runtime": 33.74727575480938, "a_collisions": 2927, "o_collisions": 1756}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-076"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.09375, "CSR": 0.0, "ep_length": 127, "SoC": 7788, "makespan": 128, "avg_agents_density": 0.25124139183997835, "runtime": 34.229089330881834, "a_collisions": 3190, "o_collisions": 2433}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-077"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.15625, "CSR": 0.0, "ep_length": 127, "SoC": 7497, "makespan": 128, "avg_agents_density": 0.24537948679456195, "runtime": 35.2752688806504, "a_collisions": 2658, "o_collisions": 2022}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-078"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.203125, "CSR": 0.0, "ep_length": 127, "SoC": 7152, "makespan": 128, "avg_agents_density": 0.22572485642440748, "runtime": 34.98773776181042, "a_collisions": 2884, "o_collisions": 1603}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-079"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 6857, "makespan": 128, "avg_agents_density": 0.2240803931585354, "runtime": 34.0676149725914, "a_collisions": 2495, "o_collisions": 2249}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-080"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 7334, "makespan": 128, "avg_agents_density": 0.22831016361298212, "runtime": 34.63439537584782, "a_collisions": 2434, "o_collisions": 1475}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-081"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7703, "makespan": 128, "avg_agents_density": 0.2161478074374737, "runtime": 34.501464957371354, "a_collisions": 2372, "o_collisions": 2617}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-082"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 7074, "makespan": 128, "avg_agents_density": 0.20217195431269389, "runtime": 34.79010730981827, "a_collisions": 2815, "o_collisions": 2008}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-083"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7850, "makespan": 128, "avg_agents_density": 0.23426257978654544, "runtime": 35.52887606434524, "a_collisions": 2462, "o_collisions": 2399}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-084"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.15625, "CSR": 0.0, "ep_length": 127, "SoC": 7829, "makespan": 128, "avg_agents_density": 0.2285826318354887, "runtime": 34.924352679401636, "a_collisions": 2097, "o_collisions": 2373}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-085"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 7387, "makespan": 128, "avg_agents_density": 0.23277086301365219, "runtime": 34.09678362123668, "a_collisions": 2546, "o_collisions": 2294}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-086"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 8063, "makespan": 128, "avg_agents_density": 0.23026932799147412, "runtime": 34.42491740360856, "a_collisions": 2915, "o_collisions": 2170}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-087"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.09375, "CSR": 0.0, "ep_length": 127, "SoC": 7790, "makespan": 128, "avg_agents_density": 0.19567657721572296, "runtime": 33.49562309868634, "a_collisions": 2745, "o_collisions": 2800}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-088"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 7214, "makespan": 128, "avg_agents_density": 0.2556852430539641, "runtime": 34.337026469409466, "a_collisions": 2424, "o_collisions": 1894}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-089"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 7787, "makespan": 128, "avg_agents_density": 0.2543487076139596, "runtime": 33.19674887135625, "a_collisions": 2917, "o_collisions": 1935}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-090"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 7681, "makespan": 128, "avg_agents_density": 0.22640848827881271, "runtime": 34.446210442110896, "a_collisions": 2709, "o_collisions": 1821}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-091"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 7572, "makespan": 128, "avg_agents_density": 0.22177850051586986, "runtime": 33.962702576071024, "a_collisions": 2569, "o_collisions": 1968}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-092"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 7910, "makespan": 128, "avg_agents_density": 0.18900981075609774, "runtime": 35.804015301167965, "a_collisions": 2072, "o_collisions": 2198}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-093"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7757, "makespan": 128, "avg_agents_density": 0.25460076064269427, "runtime": 34.803507912904024, "a_collisions": 2676, "o_collisions": 2529}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-094"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.09375, "CSR": 0.0, "ep_length": 127, "SoC": 7903, "makespan": 128, "avg_agents_density": 0.24102960909423504, "runtime": 34.14841961674392, "a_collisions": 2004, "o_collisions": 2539}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-095"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.171875, "CSR": 0.0, "ep_length": 127, "SoC": 7603, "makespan": 128, "avg_agents_density": 0.23847102483526955, "runtime": 34.43707953393459, "a_collisions": 2214, "o_collisions": 2250}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-096"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7771, "makespan": 128, "avg_agents_density": 0.23164419958031182, "runtime": 34.795026594772935, "a_collisions": 2993, "o_collisions": 1917}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-097"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.078125, "CSR": 0.0, "ep_length": 127, "SoC": 7920, "makespan": 128, "avg_agents_density": 0.27824048265063067, "runtime": 35.705166075378656, "a_collisions": 2545, "o_collisions": 2465}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-098"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.234375, "CSR": 0.0, "ep_length": 127, "SoC": 7418, "makespan": 128, "avg_agents_density": 0.24980049436950097, "runtime": 34.59140202216804, "a_collisions": 2831, "o_collisions": 2059}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-099"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 7299, "makespan": 128, "avg_agents_density": 0.20450627269428012, "runtime": 35.03957397304475, "a_collisions": 2015, "o_collisions": 1872}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-100"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7932, "makespan": 128, "avg_agents_density": 0.20027510229865225, "runtime": 36.16134111210704, "a_collisions": 2165, "o_collisions": 2441}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-101"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7516, "makespan": 128, "avg_agents_density": 0.21582143958476227, "runtime": 34.86985141970217, "a_collisions": 2164, "o_collisions": 2347}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-102"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.234375, "CSR": 0.0, "ep_length": 127, "SoC": 7165, "makespan": 128, "avg_agents_density": 0.2231037224974157, "runtime": 33.56122827902436, "a_collisions": 2582, "o_collisions": 1881}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-103"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.171875, "CSR": 0.0, "ep_length": 127, "SoC": 7471, "makespan": 128, "avg_agents_density": 0.19993931254558944, "runtime": 35.57830326445401, "a_collisions": 1932, "o_collisions": 2173}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-104"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.125, "CSR": 0.0, "ep_length": 127, "SoC": 7795, "makespan": 128, "avg_agents_density": 0.2002108998025945, "runtime": 35.35646031796932, "a_collisions": 2096, "o_collisions": 2296}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-105"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.203125, "CSR": 0.0, "ep_length": 127, "SoC": 7006, "makespan": 128, "avg_agents_density": 0.21722846476168528, "runtime": 34.86564366519451, "a_collisions": 2775, "o_collisions": 1878}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-106"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7514, "makespan": 128, "avg_agents_density": 0.24340477388399143, "runtime": 34.830348970368505, "a_collisions": 2839, "o_collisions": 2102}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-107"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7759, "makespan": 128, "avg_agents_density": 0.2721056161151994, "runtime": 34.2474361974746, "a_collisions": 2297, "o_collisions": 2392}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-108"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.09375, "CSR": 0.0, "ep_length": 127, "SoC": 7872, "makespan": 128, "avg_agents_density": 0.22951157426489638, "runtime": 34.615319184958935, "a_collisions": 2439, "o_collisions": 2278}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-109"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.109375, "CSR": 0.0, "ep_length": 127, "SoC": 7896, "makespan": 128, "avg_agents_density": 0.20668642023030126, "runtime": 35.24494894593954, "a_collisions": 2255, "o_collisions": 2452}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-110"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 7033, "makespan": 128, "avg_agents_density": 0.2556477593423449, "runtime": 34.12930995039642, "a_collisions": 3065, "o_collisions": 1817}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-111"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.0625, "CSR": 0.0, "ep_length": 127, "SoC": 8085, "makespan": 128, "avg_agents_density": 0.26916069365138007, "runtime": 34.95547562651336, "a_collisions": 2713, "o_collisions": 2436}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-112"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 7134, "makespan": 128, "avg_agents_density": 0.2543593968323267, "runtime": 34.156362384557724, "a_collisions": 3269, "o_collisions": 1703}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-113"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7586, "makespan": 128, "avg_agents_density": 0.26021539447715225, "runtime": 34.934985026717186, "a_collisions": 2812, "o_collisions": 2006}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-114"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.09375, "CSR": 0.0, "ep_length": 127, "SoC": 7681, "makespan": 128, "avg_agents_density": 0.23164454641294882, "runtime": 34.55654956959188, "a_collisions": 2127, "o_collisions": 2124}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-115"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.0625, "CSR": 0.0, "ep_length": 127, "SoC": 7957, "makespan": 128, "avg_agents_density": 0.2843151191297548, "runtime": 34.539096131920815, "a_collisions": 2468, "o_collisions": 2351}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-116"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.234375, "CSR": 0.0, "ep_length": 127, "SoC": 7163, "makespan": 128, "avg_agents_density": 0.24678133982009595, "runtime": 34.239993296563625, "a_collisions": 2745, "o_collisions": 2074}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-117"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7652, "makespan": 128, "avg_agents_density": 0.24449535528484884, "runtime": 33.990859584882855, "a_collisions": 2408, "o_collisions": 2034}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-118"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.09375, "CSR": 0.0, "ep_length": 127, "SoC": 7971, "makespan": 128, "avg_agents_density": 0.22131750598464428, "runtime": 33.230614038184285, "a_collisions": 2394, "o_collisions": 2394}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-119"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.265625, "CSR": 0.0, "ep_length": 127, "SoC": 6996, "makespan": 128, "avg_agents_density": 0.18089536834940698, "runtime": 34.433674624189734, "a_collisions": 1993, "o_collisions": 2335}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-120"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.140625, "CSR": 0.0, "ep_length": 127, "SoC": 7697, "makespan": 128, "avg_agents_density": 0.21667007893022336, "runtime": 35.10117031633854, "a_collisions": 2444, "o_collisions": 2261}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-121"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 7407, "makespan": 128, "avg_agents_density": 0.2055091192579587, "runtime": 35.53043342754245, "a_collisions": 2305, "o_collisions": 2011}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-122"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.21875, "CSR": 0.0, "ep_length": 127, "SoC": 6913, "makespan": 128, "avg_agents_density": 0.23015386239111066, "runtime": 34.33068894036114, "a_collisions": 2832, "o_collisions": 1791}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-123"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.0625, "CSR": 0.0, "ep_length": 127, "SoC": 7886, "makespan": 128, "avg_agents_density": 0.19795831365999417, "runtime": 34.745227698236704, "a_collisions": 2383, "o_collisions": 2050}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-124"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.15625, "CSR": 0.0, "ep_length": 127, "SoC": 7584, "makespan": 128, "avg_agents_density": 0.23751663518445637, "runtime": 34.42741144448519, "a_collisions": 2085, "o_collisions": 2435}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-125"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.046875, "CSR": 0.0, "ep_length": 127, "SoC": 8075, "makespan": 128, "avg_agents_density": 0.2494681298873521, "runtime": 36.491910764947534, "a_collisions": 3521, "o_collisions": 2088}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-126"}, "algorithm": "MAMBA"}, {"metrics": {"ISR": 0.1875, "CSR": 0.0, "ep_length": 127, "SoC": 7250, "makespan": 128, "avg_agents_density": 0.23468267329058187, "runtime": 41.14867356233299, "a_collisions": 2607, "o_collisions": 2152}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-127"}, "algorithm": "MAMBA"}]